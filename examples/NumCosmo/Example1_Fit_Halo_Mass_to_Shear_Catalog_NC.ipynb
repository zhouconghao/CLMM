{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit halo mass to shear profile: 1. ideal data\n",
    "\n",
    "_the LSST-DESC CLMM team_\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use `clmm` to estimate a WL halo mass of a galaxy cluster in the ideal case: i) all galaxies on a single source plane, ii) no redshift errors, iii) no shape noise. The steps below correspond to:\n",
    "- Setting things up, with the proper imports.\n",
    "- Generating an ideal mock dataset.\n",
    "- Computing the binned reduced tangential shear profile for two different binning scheme.\n",
    "- Setting up the model to be fitted to the data.\n",
    "- Perform a simple fit using NumCosmo tools to compute the best-fit and the Fisher Matrix, and visualize the results.\n",
    "\n",
    "Note that this notebook is equivalent to `Example1_Fit_Halo_Mass_to_Shear_Catalog.ipynb` except for the statistical analysis, where here we use some NumCosmo tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NumCosmo\n",
    "import os\n",
    "import sys\n",
    "import gi\n",
    "\n",
    "gi.require_version(\"NumCosmo\", \"1.0\")\n",
    "gi.require_version(\"NumCosmoMath\", \"1.0\")\n",
    "from gi.repository import GObject\n",
    "from gi.repository import NumCosmo as Nc\n",
    "from gi.repository import NumCosmoMath as Ncm\n",
    "\n",
    "os.environ[\"CLMM_MODELING_BACKEND\"] = \"nc\"\n",
    "\n",
    "__name__ = \"NcContext\"\n",
    "\n",
    "Ncm.cfg_init()\n",
    "Ncm.cfg_set_log_handler(lambda msg: sys.stdout.write(msg) and sys.stdout.flush())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import `clmm`'s core modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clmm\n",
    "import clmm.dataops as da\n",
    "import clmm.galaxycluster as gc\n",
    "import clmm.theory as theory\n",
    "from clmm import Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we know which version we're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clmm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import support modules for a specific data set.\n",
    "`clmm` includes support modules that enable the user to generate mock data in a format compatible with `clmm`.\n",
    "We also provide support modules for processing other specific data sets for use with `clmm`.\n",
    "Any existing support module can be used as a template for creating a new support module for another data set.\n",
    "If you do make such a support module, please do consider making a pull request so we can add it for others to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support import mock_data as mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create mock data, we need to define a true cosmology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_cosmo = Cosmology(H0=70.0, Omega_dm0=0.27 - 0.045, Omega_b0=0.045, Omega_k0=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set some parameters for a mock galaxy cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = mock_cosmo\n",
    "cluster_id = \"Awesome_cluster\"\n",
    "cluster_m = 1.0e15  # M200,m [Msun]\n",
    "cluster_z = 0.3  # Cluster's redshift\n",
    "src_z = 0.8  # Background galaxies' redshifts (single source plane)\n",
    "concentration = 4\n",
    "ngals = 10000  # Number of galaxies\n",
    "cluster_ra = 0.0\n",
    "cluster_dec = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the `mock_data` support module to generate a new galaxy catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_data = mock.generate_galaxy_catalog(\n",
    "    cluster_m, cluster_z, concentration, cosmo, src_z, ngals=ngals\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This galaxy catalog is then converted to a `clmm.GalaxyCluster` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec, cluster_z, ideal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `clmm.GalaxyCluster` object can be pickled and saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_object.save(\"mock_GC.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any saved `clmm.GalaxyCluster` object may be read in for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = clmm.GalaxyCluster.load(\"mock_GC.pkl\")\n",
    "print(\"Cluster info = ID:\", cl.unique_id, \"; ra:\", cl.ra, \"; dec:\", cl.dec, \"; z_l :\", cl.z)\n",
    "print(\"The number of source galaxies is :\", len(cl.galcat))\n",
    "\n",
    "# Lens position and redshift\n",
    "ra_l = cl.ra\n",
    "dec_l = cl.dec\n",
    "z = cl.z\n",
    "# Galaxies: ellipticities, position (RA, DEC), redshift\n",
    "e1 = cl.galcat[\"e1\"]\n",
    "e2 = cl.galcat[\"e2\"]\n",
    "ra_s = cl.galcat[\"ra\"]\n",
    "dec_s = cl.galcat[\"dec\"]\n",
    "z_s = cl.galcat[\"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the distribution of galaxies on the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 15\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "hb = fig.gca().hexbin(ra_s, dec_s, gridsize=50)\n",
    "\n",
    "cb = fig.colorbar(hb)\n",
    "cb.set_label(\"Number of sources in bin\", fontsize=fsize)\n",
    "\n",
    "plt.gca().set_xlabel(r\"$\\Delta RA$\", fontsize=fsize)\n",
    "plt.gca().set_ylabel(r\"$\\Delta Dec$\", fontsize=fsize)\n",
    "plt.gca().set_title(\"Source Galaxies\", fontsize=fsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm` separates cosmology-dependent and cosmology-independent functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving observables\n",
    "\n",
    "We first demonstrate a few of the procedures one can perform on data without assuming a cosmology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing shear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.dataops.compute_tangential_and_cross_components` calculates the tangential and cross shears for each source galaxy in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, g_t, g_x = da.compute_tangential_and_cross_components(\n",
    "    ra_l, dec_l, ra_s, dec_s, e1, e2, geometry=\"flat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the shear field at each galaxy location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "fig.gca().loglog(theta, g_t, \".\")\n",
    "plt.ylabel(\"reduced shear\", fontsize=fsize)\n",
    "plt.xlabel(\"angular distance [rad]\", fontsize=fsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radially binning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare the reconstructed mass under two different bin definitions. \n",
    "\n",
    "Note binning would cause fitted mass to be slightly larger than input mass. The reason is that g(r), the tangential reduced shear along cluster radius, is a convex function -- the function value after binning would be larger, but the bias becomes smaller as bin number increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges1 = da.make_bins(0.01, 3.7, 50)\n",
    "bin_edges2 = da.make_bins(0.01, 3.7, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.dataops.make_radial_profile` evaluates the average shear of the galaxy catalog in bins of radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = da.make_radial_profile(\n",
    "    [g_t, g_x, z_s],\n",
    "    theta,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=bin_edges1,\n",
    "    cosmo=cosmo,\n",
    "    z_lens=z,\n",
    "    include_empty_bins=False,\n",
    ")\n",
    "res2 = da.make_radial_profile(\n",
    "    [g_t, g_x, z_s],\n",
    "    theta,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=bin_edges2,\n",
    "    cosmo=cosmo,\n",
    "    z_lens=z,\n",
    "    include_empty_bins=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we set `include_empty_bins=False` explicitly here even though it is the default behavior. Setting the argument to `True` would also return empty bins (that is, bins with *at most one* data point in them), which would have to be excluded manually when fitting, though it might be useful e.g., when combining datasets. To clarify the behavior, consider the following comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_with_empty = da.make_radial_profile(\n",
    "    [g_t, g_x, z_s],\n",
    "    theta,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=1000,\n",
    "    cosmo=cosmo,\n",
    "    z_lens=z,\n",
    "    include_empty_bins=True,\n",
    ")\n",
    "# this is the default behavior\n",
    "res_without_empty = da.make_radial_profile(\n",
    "    [g_t, g_x, z_s],\n",
    "    theta,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=1000,\n",
    "    cosmo=cosmo,\n",
    "    z_lens=z,\n",
    "    include_empty_bins=False,\n",
    ")\n",
    "res_with_empty[\"n_src\"].size, res_without_empty[\"n_src\"].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e., 108 bins have fewer than two sources in them and are excluded by default (when setting the random seed to 11)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later use, we'll define some variables for the binned radius and tangential shear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_profile1 = res1[\"p_0\"]\n",
    "r1 = res1[\"radius\"]\n",
    "z1 = res1[\"p_2\"]\n",
    "\n",
    "gt_profile2 = res2[\"p_0\"]\n",
    "r2 = res2[\"radius\"]\n",
    "z2 = res2[\"p_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the radially binned shear for our mock galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "fig.gca().loglog(r1, gt_profile1, \".\", label=\"50 bins\")\n",
    "fig.gca().loglog(r2, gt_profile2, \"+\", markersize=15, label=\"10 bins\")\n",
    "plt.legend(fontsize=fsize)\n",
    "\n",
    "plt.gca().set_title(r\"Binned shear of source galaxies\", fontsize=fsize)\n",
    "plt.gca().set_xlabel(r\"$r\\;[Mpc]$\", fontsize=fsize)\n",
    "plt.gca().set_ylabel(r\"$g_t$\", fontsize=fsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run `make_radial_profile` direct on a `clmm.GalaxyCluster` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.compute_tangential_and_cross_components()  # You need to add the shear components first\n",
    "cl.make_radial_profile(\"Mpc\", bins=1000, cosmo=cosmo, include_empty_bins=False)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running `clmm.GalaxyCluster.make_radial_profile` object, the object acquires the `clmm.GalaxyCluster.profile` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in cl.profile.colnames:\n",
    "    cl.profile[n].format = \"%6.3e\"\n",
    "cl.profile.pprint(max_width=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the data\n",
    "\n",
    "We next demonstrate a few of the procedures one can perform once a cosmology has been chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a halo model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we model using the OO inteface, we also use NumCosmo statistical framework to perform the analysis. Below we create an object based on NumCosmo NcmDataGaussDiag (Gaussian likelihood with a diagonal covariance matrix) object. To connect with the C interface the object must implement the methods: `do_get_length`, `do_get_dof`, `do_begin`, `do_prepare` and `do_mean_func`. The last method is responsible to compute the theoretical predictions. In the param_set_ftype calls below one can change between FREE/FIXED to include/exclude the parameter from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussGammaT(Ncm.DataGaussDiag):\n",
    "    z_cluster = GObject.Property(type=float, flags=GObject.PARAM_READWRITE)\n",
    "    z_source = GObject.Property(type=Ncm.Vector, flags=GObject.PARAM_READWRITE)\n",
    "    r_source = GObject.Property(type=Ncm.Vector, flags=GObject.PARAM_READWRITE)\n",
    "\n",
    "    def __init__(self, z_cluster, r_source, z_source, gt_profile, moo=None):\n",
    "        Ncm.DataGaussDiag.__init__(self, n_points=len(gt_profile))\n",
    "\n",
    "        self.moo = moo if moo else clmm.Modeling()\n",
    "\n",
    "        assert len(gt_profile) == len(z_source)\n",
    "        assert len(gt_profile) == len(r_source)\n",
    "\n",
    "        self.set_size(len(gt_profile))\n",
    "\n",
    "        self.props.z_cluster = z_cluster\n",
    "        self.props.z_source = Ncm.Vector.new_array(z_source)\n",
    "        self.props.r_source = Ncm.Vector.new_array(r_source)\n",
    "\n",
    "        self.y.set_array(gt_profile)\n",
    "\n",
    "        self.sigma.set_all(\n",
    "            1.0e-2\n",
    "        )  # Diagonal covariance matrix: all points have the same standard deviation value\n",
    "\n",
    "        self.set_init(True)\n",
    "\n",
    "    # Once the NcmDataGaussDiag is initialized, its parent class variable np is set with the n_points value.\n",
    "    def do_get_length(self):\n",
    "        return self.np\n",
    "\n",
    "    def do_get_dof(self):\n",
    "        return self.np\n",
    "\n",
    "    def do_begin(self):\n",
    "        pass\n",
    "\n",
    "    def do_prepare(self, mset):\n",
    "        self.moo.set_mset(mset)\n",
    "\n",
    "    def do_mean_func(self, mset, vp):\n",
    "        vp.set_array(\n",
    "            self.moo.eval_reduced_tangential_shear(\n",
    "                self.props.r_source.dup_array(),\n",
    "                self.props.z_cluster,\n",
    "                self.props.z_source.dup_array(),\n",
    "            )\n",
    "        )\n",
    "        return\n",
    "\n",
    "\n",
    "GObject.type_register(GaussGammaT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model set (NcmMset), data set (NcmDataset) and NcmLikelihood objects to carry out a statistical analysis. \n",
    "\n",
    "The method `param_set_ftype` defines the parameters that can be fitted: `mid` - to which model set the parameter belongs to, `pid` - parameters' id, NcmParamType (FREE or FIXED) to say if the parameter will be fitted or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moo1 = clmm.Modeling(massdef=\"mean\", delta_mdef=200, halo_profile_model=\"nfw\")\n",
    "moo1.set_cosmo(cosmo)\n",
    "moo1.set_concentration(4.0)\n",
    "\n",
    "moo2 = clmm.Modeling(massdef=\"mean\", delta_mdef=200, halo_profile_model=\"nfw\")\n",
    "moo2.set_cosmo(cosmo)\n",
    "moo2.set_concentration(4.0)\n",
    "\n",
    "ggt1 = GaussGammaT(z_cluster=cluster_z, r_source=r1, z_source=z1, gt_profile=gt_profile1, moo=moo1)\n",
    "ggt2 = GaussGammaT(z_cluster=cluster_z, r_source=r2, z_source=z2, gt_profile=gt_profile2, moo=moo2)\n",
    "\n",
    "mset1 = ggt1.moo.get_mset()\n",
    "mset2 = ggt2.moo.get_mset()\n",
    "\n",
    "# Parameters: cluster mass (log base 10) and concentration\n",
    "log10MDelta_pi = mset1.param_get_by_full_name(\"NcHaloDensityProfile:log10MDelta\")\n",
    "cDelta_pi = mset1.param_get_by_full_name(\"NcHaloDensityProfile:cDelta\")\n",
    "\n",
    "mset1.param_set_ftype(log10MDelta_pi.mid, log10MDelta_pi.pid, Ncm.ParamType.FREE)\n",
    "mset1.param_set_ftype(cDelta_pi.mid, cDelta_pi.pid, Ncm.ParamType.FIXED)\n",
    "mset1.prepare_fparam_map()\n",
    "\n",
    "mset2.param_set_ftype(log10MDelta_pi.mid, log10MDelta_pi.pid, Ncm.ParamType.FREE)\n",
    "mset2.param_set_ftype(cDelta_pi.mid, cDelta_pi.pid, Ncm.ParamType.FIXED)\n",
    "mset2.prepare_fparam_map()\n",
    "\n",
    "dset1 = Ncm.Dataset.new()\n",
    "dset1.append_data(ggt1)\n",
    "lh1 = Ncm.Likelihood.new(dset1)\n",
    "\n",
    "dset2 = Ncm.Dataset.new()\n",
    "dset2.append_data(ggt2)\n",
    "lh2 = Ncm.Likelihood.new(dset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting parameters: Fisher Matrix\n",
    "\n",
    "The NcmFit object receives the NcmLikelihood and NcmMset objects. The user also indicates the fitting algorithm and the numerical differentiation method.  \n",
    "Functions `run` and `fisher` computes the best-fit and the fisher matrix, respectively. `log_info` prints the complete information about the data used, models and its parameters, and `log_covar` prints the best-fit along with the error-bar and the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 = Ncm.Fit.new(Ncm.FitType.NLOPT, \"ln-neldermead\", lh1, mset1, Ncm.FitGradType.NUMDIFF_FORWARD)\n",
    "fit2 = Ncm.Fit.new(Ncm.FitType.NLOPT, \"ln-neldermead\", lh2, mset2, Ncm.FitGradType.NUMDIFF_FORWARD)\n",
    "\n",
    "fit1.run(Ncm.FitRunMsgs.SIMPLE)\n",
    "fit1.fisher()\n",
    "fit1.log_info()\n",
    "fit1.log_covar()\n",
    "\n",
    "fit2.run(Ncm.FitRunMsgs.SIMPLE)\n",
    "fit2.fisher()\n",
    "fit2.log_info()\n",
    "fit2.log_covar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the reduced tangential shear predicted by the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.logspace(-2, np.log10(5), 100)\n",
    "\n",
    "gt_model1 = moo1.eval_reduced_tangential_shear(rr, cluster_z, src_z)\n",
    "gt_model2 = moo2.eval_reduced_tangential_shear(rr, cluster_z, src_z)\n",
    "\n",
    "m_est1 = 10 ** (mset1.param_get(log10MDelta_pi.mid, log10MDelta_pi.pid))\n",
    "m_est2 = 10 ** (mset2.param_get(log10MDelta_pi.mid, log10MDelta_pi.pid))\n",
    "\n",
    "print(\"mest1 % 22.15g mest2 % 22.15g\" % (m_est1, m_est2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the two predictions of reduced tangential shear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "fig.gca().scatter(\n",
    "    r1, gt_profile1, color=\"orange\", label=\"binned mock data 1, M_input = %.3e Msun/h\" % cluster_m\n",
    ")\n",
    "fig.gca().plot(rr, gt_model1, color=\"orange\", label=\"best fit model 1, M_fit = %.3e\" % m_est1)\n",
    "\n",
    "fig.gca().scatter(\n",
    "    r2,\n",
    "    gt_profile2,\n",
    "    color=\"blue\",\n",
    "    alpha=0.5,\n",
    "    label=\"binned mock data 2, M_input = %.3e Msun/h\" % cluster_m,\n",
    ")\n",
    "fig.gca().plot(\n",
    "    rr,\n",
    "    gt_model2,\n",
    "    color=\"blue\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.5,\n",
    "    label=\"best fit model 2, M_fit = %.3e\" % m_est2,\n",
    ")\n",
    "\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"R [Mpc]\", fontsize=fsize)\n",
    "plt.ylabel(\"reduced tangential shear\", fontsize=fsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

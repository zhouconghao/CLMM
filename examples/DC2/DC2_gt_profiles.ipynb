{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare tangential shear profiles from the extragalactic and object catalogs for DC2 Run 2.2i\n",
    "\n",
    "This notebook can be run at NERSC or CC-IN2P3 where the DESC DC2 products are stored. You need to be a DESC member to be able to access those. The DC2 catalog-related imports below (`FoFCatalogMatching`, `GCR` and `GCRCatalogs`) are readily available from the `desc` conda environement at NERC or CC-IN2P3. If working outside such environment, these packagea first need to be installed. \n",
    "\n",
    "This was put together using:\n",
    "- the DC2 analysis tutorials (in particular [matching_fof.ipynb](https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/matching_fof.ipynb) and [object_gcr_2_lensing_cuts.ipynb](https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/object_gcr_2_lensing_cuts.ipynb))\n",
    "- the CLMM usage examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from astropy.table import Table\n",
    "\n",
    "# DC2 catalog-related imports\n",
    "import FoFCatalogMatching\n",
    "import GCRCatalogs\n",
    "from GCR import GCRQuery\n",
    "\n",
    "# CLMM imports\n",
    "import clmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the catalogs\n",
    "- DC2 object catalog\n",
    "- DC2 extragalactic catalog (cosmoDC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cat = GCRCatalogs.load_catalog(\"dc2_object_run2.2i_dr6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extragalactic_cat = GCRCatalogs.load_catalog(\"cosmoDC2_v1.1.4_small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identify one halo in the extragalactic catalog\n",
    "Choosing the most massive one below z = 0.4. The `halo_mass` field of the cosmoDC2 catalog gives the mass in units of M$_{\\odot}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of massive halos in a given redshift and mass range\n",
    "mmin = 5.0e14  # Msun\n",
    "zmax = 0.4\n",
    "\n",
    "massive_halos = extragalactic_cat.get_quantities(\n",
    "    [\"halo_mass\", \"hostHaloMass\", \"redshift\", \"ra\", \"dec\", \"halo_id\"],\n",
    "    filters=[f\"halo_mass > {mmin}\", \"is_central==True\", f\"redshift<{zmax}\"],\n",
    ")\n",
    "\n",
    "N_cl = len(massive_halos[\"halo_mass\"])\n",
    "print(f\"There are {N_cl} clusters in that mass and redshift ranges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the most massive one\n",
    "select = massive_halos[\"halo_mass\"] == np.max(massive_halos[\"halo_mass\"])\n",
    "ra_cl = massive_halos[\"ra\"][select][0]\n",
    "dec_cl = massive_halos[\"dec\"][select][0]\n",
    "z_cl = massive_halos[\"redshift\"][select][0]\n",
    "mass_cl = massive_halos[\"halo_mass\"][select][0]\n",
    "id_cl = massive_halos[\"halo_id\"][select][0]\n",
    "\n",
    "print(\n",
    "    f\"The most massive cluster is halo {id_cl}, in ra = {ra_cl:.2f} deg, dec = {dec_cl:.2f} deg, z = {z_cl:.2f}, with mass = {mass_cl:.2e} Msun\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selection of background galaxies around the cluster\n",
    "- Define cuts on the cosmoDC2 and object catalogs. \n",
    "    - Box of 0.7 deg around the cluster center\n",
    "    - Galaxies with z > z_cluster + 0.1\n",
    "    - Galaxies with mag_i < 24.5\n",
    "- We also add some WL quality cuts for the object catalog.\n",
    "- The two catalogs will then be matched to end up with the same selection of galaxies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Cut definition\n",
    "\n",
    "NB: the object catalog quality cuts follow that given in the [object_gcr_2_lensing_cuts.ipynb](https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/object_gcr_2_lensing_cuts.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coordinate filter to be applied applied to both extragalactic and object catalog\n",
    "ra_min, ra_max = ra_cl - 0.35, ra_cl + 0.35\n",
    "dec_min, dec_max = dec_cl - 0.35, dec_cl + 0.35\n",
    "\n",
    "coord_filters = [\n",
    "    f\"ra >= {ra_min}\",\n",
    "    f\"ra < {ra_max}\",\n",
    "    f\"dec >= {dec_min}\",\n",
    "    f\"dec < {dec_max}\",\n",
    "]\n",
    "\n",
    "# Redshift cut to be applied to the extragalactic catalog. The object catalog does not have redshift information.\n",
    "z_min = z_cl + 0.1\n",
    "redshift_filters = [\n",
    "    (np.isfinite, \"redshift\"),\n",
    "    f\"redshift > {z_min}\",\n",
    "]\n",
    "\n",
    "# Magnitude cut to be applied to both catalogs\n",
    "mag_filters = [\n",
    "    (np.isfinite, \"mag_i\"),\n",
    "    \"mag_i < 24.5\",\n",
    "]\n",
    "\n",
    "# Following DC2 tutorials, basics cuts to be applied to the object catalog\n",
    "object_basic_cuts = [\n",
    "    GCRQuery(\"extendedness > 0\"),  # Extended objects\n",
    "    GCRQuery((np.isfinite, \"mag_i\")),  # Select objects that have i-band magnitudes\n",
    "    GCRQuery(\n",
    "        \"clean\"\n",
    "    ),  # The source has no flagged pixels (interpolated, saturated, edge, clipped...)\n",
    "    # and was not skipped by the deblender\n",
    "    GCRQuery(\"xy_flag == 0\"),  # Flag for centroid measurement (0 if OK)\n",
    "    GCRQuery(\n",
    "        \"ext_shapeHSM_HsmShapeRegauss_flag == 0\"\n",
    "    ),  # Flag returned by shape measurement code (0 if OK)\n",
    "    GCRQuery(\n",
    "        (np.isfinite, \"ext_shapeHSM_HsmShapeRegauss_sigma\")\n",
    "    ),  # Shape measurement uncertainty should not be NaN\n",
    "]\n",
    "\n",
    "# Adding the total ellipticity quantity to the object catalog\n",
    "object_cat.add_quantity_modifier(\n",
    "    \"shape_hsm_regauss_etot\",\n",
    "    (np.hypot, \"ext_shapeHSM_HsmShapeRegauss_e1\", \"ext_shapeHSM_HsmShapeRegauss_e2\"),\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Following DC2 tutorials, additional WL quality cuts to be applied to the object catalog\n",
    "object_properties_cuts = [\n",
    "    GCRQuery(\"snr_i_cModel > 10\"),  # SNR > 10\n",
    "    GCRQuery(\"mag_i_cModel < 24.5\"),  # cModel imag brighter than 24.5\n",
    "    GCRQuery(\n",
    "        \"ext_shapeHSM_HsmShapeRegauss_resolution >= 0.3\"\n",
    "    ),  # Sufficiently resolved galaxies compared to PSF\n",
    "    GCRQuery(\"shape_hsm_regauss_etot < 2\"),  # Total distortion in reasonable range\n",
    "    GCRQuery(\"ext_shapeHSM_HsmShapeRegauss_sigma <= 0.4\"),  # Shape measurement errors reasonable\n",
    "    GCRQuery(\n",
    "        \"blendedness < 10**(-0.375)\"\n",
    "    ),  # Avoid spurious detections and those contaminated by blends\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Load quantities from both catalogs, given the cuts defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extragal_data = extragalactic_cat.get_quantities(\n",
    "    [\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"shear_1\",\n",
    "        \"shear_2\",\n",
    "        \"ellipticity_1_true\",\n",
    "        \"ellipticity_2_true\",\n",
    "        \"redshift\",\n",
    "        \"convergence\",\n",
    "        \"galaxy_id\",\n",
    "    ],\n",
    "    filters=(coord_filters + mag_filters + redshift_filters),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the object catalog below, the field under scrutiny falls in tract 3448. A DM-stack installation is required to identify a tract given a set of coordinates (this was done separately from this notebook). In any case, specifying that tract using `native_filters` speeds up the process but is not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_data = object_cat.get_quantities(\n",
    "    [\"ra\", \"dec\", \"ext_shapeHSM_HsmShapeRegauss_e1\", \"ext_shapeHSM_HsmShapeRegauss_e2\", \"id\"],\n",
    "    native_filters=[\"tract == 3448\"],\n",
    "    filters=(coord_filters + object_basic_cuts + object_properties_cuts),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Match the 2 catalogs\n",
    "\n",
    "Using the `FoFCatalogMatching` method; this was examplified in the [DC2 analysis tutorial](https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/matching_fof.ipynb) and adapted to our purpose here. As mentioned in the tutorial, *`FoFCatalogMatching.match` takes a dictionary of catalogs to match and a friends-of-friends linking length. Because the \"catalog\" is not an astropy table or pandas dataframe, `len(truth_coord)` won't give the actual length of the table so we need to specify `catalog_len_getter` so that the code knows how to get the length of the catalog.*\n",
    "\n",
    "NB: `linking_lengths` is in arcsec. Here, we ask `FoFCatalogMatching` to use a linking length of 1 arcsec.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Perform the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = FoFCatalogMatching.match(\n",
    "    catalog_dict={\"extragal\": extragal_data, \"object\": object_data},\n",
    "    linking_lengths=1.0,\n",
    "    catalog_len_getter=lambda x: len(x[\"ra\"]),\n",
    ")\n",
    "\n",
    "# identify which rows are from the extragalactic catalog and which are from the object\n",
    "extragal_mask = results[\"catalog_key\"] == \"extragal\"\n",
    "object_mask = ~extragal_mask\n",
    "\n",
    "# np.bincount will give up the number of id occurrences (like histogram but with integer input)\n",
    "n_groups = results[\"group_id\"].max() + 1\n",
    "n_extragal = np.bincount(results[\"group_id\"][extragal_mask], minlength=n_groups)\n",
    "n_object = np.bincount(results[\"group_id\"][object_mask], minlength=n_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Identify one-to-one extragal/object matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_one_group_mask = np.in1d(\n",
    "    results[\"group_id\"], np.flatnonzero((n_extragal == 1) & (n_object == 1))\n",
    ")\n",
    "\n",
    "# Row indices in the *original* extragal/object catalogs for those 1-to-1 groups\n",
    "extragal_idx = results[\"row_index\"][one_to_one_group_mask & extragal_mask]\n",
    "object_idx = results[\"row_index\"][one_to_one_group_mask & object_mask]\n",
    "print(f\"Number of 1-to-1 matched objects: {len(extragal_idx)}, {len(object_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Computes the reduced tangential shear profiles from both datasets, using CLMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 First, dealing with the cosmoDC2 data.\n",
    "To measure a reduced tangential shear profile, the shape measurements must be made according to the $\\epsilon$ or reduced shear definition $g$. So first , we convert cosmoDC2 `shear1` and `shear2` quantities to reduced shear using the `convergence`. These become the `e1` and `e2` fields of the CLMM cluster galaxy catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = clmm.utils.convert_shapes_to_epsilon(\n",
    "    extragal_data[\"shear_1\"][extragal_idx],\n",
    "    extragal_data[\"shear_2\"][extragal_idx],\n",
    "    shape_definition=\"shear\",\n",
    "    kappa=extragal_data[\"convergence\"][extragal_idx],\n",
    ")\n",
    "\n",
    "# Create the background galaxy catalog as a CLMM GCData (= astropy table)\n",
    "dat = clmm.GCData(\n",
    "    [\n",
    "        extragal_data[\"ra\"][extragal_idx],\n",
    "        extragal_data[\"dec\"][extragal_idx],\n",
    "        e1,\n",
    "        e2,\n",
    "        extragal_data[\"redshift\"][extragal_idx],\n",
    "        extragal_data[\"galaxy_id\"][extragal_idx],\n",
    "    ],\n",
    "    names=(\"ra\", \"dec\", \"e1\", \"e2\", \"z\", \"id\"),\n",
    ")\n",
    "\n",
    "# Instantiate a CLMM cluster object and save it for later use.\n",
    "cl_from_cosmoDC2 = clmm.GalaxyCluster(str(id_cl), ra_cl, dec_cl, z_cl, dat)\n",
    "cl_from_cosmoDC2.save(\"cosmoDC2_GC.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Second, doing the same for the DC2 object catalog\n",
    "In the object catalog, shapes are measured by `shapeHSM` which return ellipticities according to the $\\chi$ definition. Need to convert to the $\\epsilon$ definition, once again using the conversion helper function from CLMM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1, e2 = clmm.utils.convert_shapes_to_epsilon(\n",
    "    object_data[\"ext_shapeHSM_HsmShapeRegauss_e1\"][object_idx],\n",
    "    object_data[\"ext_shapeHSM_HsmShapeRegauss_e2\"][object_idx],\n",
    "    shape_definition=\"chi\",\n",
    ")\n",
    "\n",
    "# The conversion may create NaN, so avoid these by creating a mask\n",
    "mask = np.isfinite(e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object catalog has no redshift information so we'll use the redshift of the matched galaxies in cosmoDC2 to create the GalaxyCluster object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the background galaxy catalog as a CLMM GCData (= astropy table)\n",
    "dat = clmm.GCData(\n",
    "    [\n",
    "        object_data[\"ra\"][object_idx][mask],\n",
    "        object_data[\"dec\"][object_idx][mask],\n",
    "        e1[mask],\n",
    "        e2[mask],\n",
    "        extragal_data[\"redshift\"][extragal_idx][mask],\n",
    "        object_data[\"id\"][object_idx][mask],\n",
    "    ],\n",
    "    names=(\"ra\", \"dec\", \"e1\", \"e2\", \"z\", \"id\"),\n",
    "    masked=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create the background galaxy catalog as astropy table and save it for later use\n",
    "cl_from_objectDC2 = clmm.GalaxyCluster(str(id_cl), ra_cl, dec_cl, z_cl, dat)\n",
    "cl_from_objectDC2.save(\"objectDC2_GC.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Build the reduced tangential shear profile from both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_from_objectDC2 = clmm.GalaxyCluster.load(\"objectDC2_GC.pkl\")\n",
    "cl_from_cosmoDC2 = clmm.GalaxyCluster.load(\"cosmoDC2_GC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_cosmo = extragalactic_cat.cosmology\n",
    "cosmo = clmm.Cosmology(\n",
    "    H0=dc2_cosmo.H0.value, Omega_dm0=dc2_cosmo.Om0 - dc2_cosmo.Ob0, Omega_b0=dc2_cosmo.Ob0\n",
    ")\n",
    "\n",
    "bin_edges = clmm.dataops.make_bins(0.15, 4, 10, method=\"evenlog10width\")\n",
    "\n",
    "cl_from_cosmoDC2.compute_tangential_and_cross_components(geometry=\"flat\")\n",
    "profile_from_cosmoDC2 = cl_from_cosmoDC2.make_radial_profile(\"Mpc\", bins=bin_edges, cosmo=cosmo)\n",
    "\n",
    "cl_from_objectDC2.compute_tangential_and_cross_components(geometry=\"flat\")\n",
    "profile_from_objectDC2 = cl_from_objectDC2.make_radial_profile(\"Mpc\", bins=bin_edges, cosmo=cosmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Taking into account intrinsic ellipticities from cosmoDC2\n",
    "\n",
    "So far, we've used the `shear1` and `shear2` fields of cosmoDC2, i.e., we neglected the intrinsic ellipticities of the galaxies. To account for shape noise from intrinsic ellipticities, we can use the shears and unlensed ellipticities available in the cosmoDC2 catalog to build lensed ellipticities (this is done using the `compute_lensed_ellipticity` function available in CLMM - see the documentation for details). The latter can then be used to bluid a CLMM cluster object. The resulting tangential shear profile will then include shape noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es1 = extragal_data[\"ellipticity_1_true\"]\n",
    "es2 = extragal_data[\"ellipticity_2_true\"]\n",
    "gamma1 = extragal_data[\"shear_1\"]\n",
    "gamma2 = extragal_data[\"shear_2\"]\n",
    "kappa = extragal_data[\"convergence\"]\n",
    "\n",
    "extragal_data[\"ellipticity_1\"] = clmm.utils.compute_lensed_ellipticity(\n",
    "    es1, es2, gamma1, gamma2, kappa\n",
    ")[0]\n",
    "extragal_data[\"ellipticity_2\"] = clmm.utils.compute_lensed_ellipticity(\n",
    "    es1, es2, gamma1, gamma2, kappa\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new CLMM cluster object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = clmm.GCData(\n",
    "    [\n",
    "        extragal_data[\"ra\"][extragal_idx],\n",
    "        extragal_data[\"dec\"][extragal_idx],\n",
    "        extragal_data[\"ellipticity_1\"][extragal_idx],\n",
    "        extragal_data[\"ellipticity_2\"][extragal_idx],\n",
    "        extragal_data[\"redshift\"][extragal_idx],\n",
    "        extragal_data[\"galaxy_id\"][extragal_idx],\n",
    "    ],\n",
    "    names=(\"ra\", \"dec\", \"e1\", \"e2\", \"z\", \"id\"),\n",
    ")\n",
    "\n",
    "cl_from_cosmoDC2_with_e1e2 = clmm.GalaxyCluster(str(id_cl), ra_cl, dec_cl, z_cl, dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the reduced shear profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_from_cosmoDC2_with_e1e2.compute_tangential_and_cross_components(geometry=\"flat\")\n",
    "profile_from_cosmoDC2_with_e1e2 = cl_from_cosmoDC2_with_e1e2.make_radial_profile(\n",
    "    \"Mpc\", bins=bin_edges, cosmo=cosmo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualize the results for the three profiles, obtained from the same galaxies in the two catalogs\n",
    "- from cosmoDC2, neglecting shape noise (blue points)\n",
    "- from cosmoDC2, including shape noise (orange)\n",
    "- for the DC2 object catalog (green, where the galaxies redshifts taken from cosmoDC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(\n",
    "    profile_from_cosmoDC2[\"radius\"],\n",
    "    profile_from_cosmoDC2[\"gt\"],\n",
    "    profile_from_cosmoDC2[\"gt_err\"],\n",
    "    marker=\"o\",\n",
    "    label=\"from cosmoDC2 g1g2\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    profile_from_cosmoDC2_with_e1e2[\"radius\"],\n",
    "    profile_from_cosmoDC2_with_e1e2[\"gt\"],\n",
    "    profile_from_cosmoDC2[\"gt_err\"],\n",
    "    label=\"from cosmoDC2 e1e2\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    profile_from_objectDC2[\"radius\"],\n",
    "    profile_from_objectDC2[\"gt\"],\n",
    "    profile_from_objectDC2[\"gt_err\"],\n",
    "    label=\"from DC2 objects e1e2\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"R (Mpc)\")\n",
    "plt.ylabel(r\"$\\langle g_t \\rangle$\")\n",
    "plt.ylim([2.0e-3, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From cosmoDC2 (orange and blue profiles above), we see the impact of shape noise at low radii (orange/blue =w/wo intrinsic ellipticities), where the number of galaxies per bin is small (see below). The error bars on the data computed by `make_shear_profile` simply corresponds to the standard error of the mean in the bin ($\\sigma_{\\rm bin}/\\sqrt{N_{\\rm gal\\_in\\_bin}}$). The errors on individual shape measurements on the DC2 object catalog have been negelected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(profile_from_cosmoDC2[\"radius\"], profile_from_cosmoDC2[\"n_src\"], marker=\"o\")\n",
    "[\n",
    "    plt.axvline(x=r, ymin=0, ymax=1e3, color=\"k\", linestyle=\":\")\n",
    "    for r in profile_from_cosmoDC2[\"radius_min\"]\n",
    "]\n",
    "plt.ylabel(\"Ngal in the bin\")\n",
    "plt.xlabel(\"R (Mpc)\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Number of galaxies in each bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example2b: Object-oriented modeling\n",
    "## Fit halo mass to shear profile using object-oriented modeling\n",
    "\n",
    "_the LSST-DESC CLMM team_\n",
    "\n",
    "\n",
    "This notebooks performs the same set of operations as `Example2_Fit_halo_Mass_to_Shear_Catalog.ipynb`, but uses instead the object-oriented interface to build the model. Here the NumCosmo theory backend is used but you may try the `CCL` or `cluster_toolkit` backend instead. For that, change the line `os.environ['CLMM_MODELING_BACKEND'] = 'nc'` to :\n",
    " - `os.environ['CLMM_MODELING_BACKEND'] = 'ccl'` - for `CCL`\n",
    " - `os.environ['CLMM_MODELING_BACKEND'] = 'ct'` - for `cluster_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\n",
    "    \"CLMM_MODELING_BACKEND\"\n",
    "] = \"ccl\"  # here you may choose ccl, nc (NumCosmo) or ct (cluster_toolkit)\n",
    "import clmm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from clmm.support.sampler import fitters\n",
    "\n",
    "clmm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import `clmm`'s core modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clmm.dataops as da\n",
    "import clmm.galaxycluster as gc\n",
    "import clmm.theory as theory\n",
    "from clmm import Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import a support modules for a specific data sets.\n",
    "`clmm` includes support modules that enable the user to generate mock data in a format compatible with `clmm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support import mock_data as mock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making mock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create mock data, we need to define a true cosmology, which is currently done with [`astropy`'s cosmology library](http://docs.astropy.org/en/stable/cosmology/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_cosmo = Cosmology(H0=70.0, Omega_dm0=0.27 - 0.045, Omega_b0=0.045, Omega_k0=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set some parameters for a mock galaxy cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = mock_cosmo\n",
    "cluster_m = 1.0e15  # M200,m [Msun]\n",
    "cluster_z = 0.3\n",
    "concentration = 4\n",
    "ngals = 10000\n",
    "cluster_ra = 20.0\n",
    "cluster_dec = 70.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the `mock_data` support module to generate 3 galaxy catalogs:\n",
    "- `ideal_data`: all background galaxies at the same redshift.\n",
    "- `ideal_data_z`: galaxies distributed according to the Chang et al. (2013) redshift distribution.\n",
    "- `noisy_data_z`: `ideal_data_z` + photoz errors + shape noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_data = mock.generate_galaxy_catalog(\n",
    "    cluster_m,\n",
    "    cluster_z,\n",
    "    concentration,\n",
    "    cosmo,\n",
    "    0.8,\n",
    "    ngals=ngals,\n",
    "    cluster_ra=cluster_ra,\n",
    "    cluster_dec=cluster_dec,\n",
    ")\n",
    "ideal_data_z = mock.generate_galaxy_catalog(\n",
    "    cluster_m,\n",
    "    cluster_z,\n",
    "    concentration,\n",
    "    cosmo,\n",
    "    \"chang13\",\n",
    "    ngals=ngals,\n",
    "    cluster_ra=cluster_ra,\n",
    "    cluster_dec=cluster_dec,\n",
    ")\n",
    "noisy_data_z = mock.generate_galaxy_catalog(\n",
    "    cluster_m,\n",
    "    cluster_z,\n",
    "    concentration,\n",
    "    cosmo,\n",
    "    \"chang13\",\n",
    "    shapenoise=0.05,\n",
    "    photoz_sigma_unscaled=0.05,\n",
    "    ngals=ngals,\n",
    "    cluster_ra=cluster_ra,\n",
    "    cluster_dec=cluster_dec,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The galaxy catalogs are converted to a `clmm.GalaxyCluster` object and may be saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = \"CL_ideal\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec, cluster_z, ideal_data)\n",
    "gc_object.save(\"ideal_GC.pkl\")\n",
    "\n",
    "cluster_id = \"CL_ideal_z\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec, cluster_z, ideal_data_z)\n",
    "gc_object.save(\"ideal_GC_z.pkl\")\n",
    "\n",
    "cluster_id = \"CL_noisy_z\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec, cluster_z, noisy_data_z)\n",
    "gc_object.save(\"noisy_GC_z.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any saved `clmm.GalaxyCluster` object may be read in for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl1 = clmm.GalaxyCluster.load(\"ideal_GC.pkl\")  # all background galaxies at the same redshift\n",
    "cl2 = clmm.GalaxyCluster.load(\n",
    "    \"ideal_GC_z.pkl\"\n",
    ")  # background galaxies distributed according to Chang et al. (2013)\n",
    "cl3 = clmm.GalaxyCluster.load(\"noisy_GC_z.pkl\")  # same as cl2 but with photoz error and shape noise\n",
    "\n",
    "print(\"Cluster info = ID:\", cl2.unique_id, \"; ra:\", cl2.ra, \"; dec:\", cl2.dec, \"; z_l :\", cl2.z)\n",
    "print(\"The number of source galaxies is :\", len(cl2.galcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(cl2.galcat[\"z\"], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing shear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.dataops.compute_tangential_and_cross_components` calculates the tangential and cross shears for each source galaxy in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1, g_t1, g_x1 = cl1.compute_tangential_and_cross_components()\n",
    "theta2, g_t2, g_x2 = cl2.compute_tangential_and_cross_components()\n",
    "theta2, g_t3, g_x3 = cl3.compute_tangential_and_cross_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radially binning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = da.make_bins(0.7, 4, 15, method=\"evenlog10width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.dataops.make_radial_profile` evaluates the average shear of the galaxy catalog in bins of radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile1 = cl1.make_radial_profile(\"Mpc\", bins=bin_edges, cosmo=cosmo)\n",
    "profile2 = cl2.make_radial_profile(\"Mpc\", bins=bin_edges, cosmo=cosmo)\n",
    "profile3 = cl3.make_radial_profile(\"Mpc\", bins=bin_edges, cosmo=cosmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running `clmm.GalaxyCluster.make_radial_profile` object, the object acquires the `clmm.GalaxyCluster.profile` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in cl1.profile.colnames:\n",
    "    cl1.profile[n].format = \"%6.3e\"\n",
    "cl1.profile.pprint(max_width=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the radially binned shear for the 3 configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "fsize = 14\n",
    "fig.gca().errorbar(\n",
    "    profile1[\"radius\"], profile1[\"gt\"], yerr=profile1[\"gt_err\"], marker=\"o\", label=\"z_src = 0.8\"\n",
    ")\n",
    "fig.gca().errorbar(\n",
    "    profile2[\"radius\"],\n",
    "    profile2[\"gt\"],\n",
    "    yerr=profile2[\"gt_err\"],\n",
    "    marker=\"o\",\n",
    "    label=\"z_src = Chang et al. (2013)\",\n",
    ")\n",
    "fig.gca().errorbar(\n",
    "    profile3[\"radius\"],\n",
    "    profile3[\"gt\"],\n",
    "    yerr=profile3[\"gt_err\"],\n",
    "    marker=\"o\",\n",
    "    label=\"z_src = Chang et al. (2013) + photoz err  + shape noise\",\n",
    ")\n",
    "\n",
    "plt.gca().set_title(r\"Binned shear of source galaxies\", fontsize=fsize)\n",
    "plt.gca().set_xlabel(r\"$r\\;[Mpc]$\", fontsize=fsize)\n",
    "plt.gca().set_ylabel(r\"$g_t$\", fontsize=fsize)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the halo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define a CLMM theory object to use with the NC or CCL backend\n",
    "moo = clmm.Modeling(massdef=\"mean\", delta_mdef=200, halo_profile_model=\"nfw\")\n",
    "moo.set_cosmo(mock_cosmo)\n",
    "moo.set_concentration(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition to be used with scipy.optimize.curve_fit\n",
    "def shear_profile_model(r, logm, z_src):\n",
    "    moo.set_mass(10.0**logm)\n",
    "    gt_model = moo.eval_reduced_tangential_shear(r, cluster_z, z_src)\n",
    "    return gt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a halo mass - highlighting bias when not accounting for the source redshift distribution in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the best-fit mass using `scipy.optimize.curve_fit`.\n",
    "\n",
    "Here, to build the model we make the WRONG assumption that the average shear in bin $i$ equals the shear at the average redshift in the bin; i.e. we assume that $\\langle g_t\\rangle_i = g_t(\\langle z\\rangle_i)$. This should not impact `cluster 1` as all sources are located at the same redshift. However, this yields a bias in the econstructed mass for `cluster 2` and `cluster 3`, where the sources followed the Chang et al. (2013) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 1:  ideal data\n",
    "popt1, pcov1 = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: shear_profile_model(r, logm, profile1[\"z\"]),\n",
    "    profile1[\"radius\"],\n",
    "    profile1[\"gt\"],\n",
    "    profile1[\"gt_err\"],\n",
    "    bounds=[13.0, 17.0],\n",
    ")\n",
    "# popt1,pcov1 = spo.curve_fit(lambda r, logm:shear_profile_model(r, logm, profile1['z']),\n",
    "#                    profile1['radius'],\n",
    "#                    profile1['gt'],\n",
    "#                    sigma=profile1['gt_err'], bounds=[13.,17.])\n",
    "\n",
    "m_est1 = 10.0 ** popt1[0]\n",
    "m_est_err1 = m_est1 * np.sqrt(pcov1[0][0]) * np.log(10)  # convert the error on logm to error on m\n",
    "\n",
    "# Cluster 2:  ideal data with redshift distribution\n",
    "popt2, pcov2 = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: shear_profile_model(r, logm, profile2[\"z\"]),\n",
    "    profile2[\"radius\"],\n",
    "    profile2[\"gt\"],\n",
    "    profile2[\"gt_err\"],\n",
    "    bounds=[13.0, 17.0],\n",
    ")\n",
    "\n",
    "m_est2 = 10.0 ** popt2[0]\n",
    "m_est_err2 = m_est2 * np.sqrt(pcov2[0][0]) * np.log(10)  # convert the error on logm to error on m\n",
    "\n",
    "# Cluster 3:  noisy data with redshift distribution\n",
    "popt3, pcov3 = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: shear_profile_model(r, logm, profile3[\"z\"]),\n",
    "    profile3[\"radius\"],\n",
    "    profile3[\"gt\"],\n",
    "    profile3[\"gt_err\"],\n",
    "    bounds=[13.0, 17.0],\n",
    ")\n",
    "\n",
    "m_est3 = 10.0 ** popt3[0]\n",
    "m_est_err3 = m_est3 * np.sqrt(pcov3[0][0]) * np.log(10)  # convert the error on logm to error on m\n",
    "\n",
    "\n",
    "print(f\"Best fit mass for cluster 1 = {m_est1:.2e} +/- {m_est_err1:.2e} Msun\")\n",
    "print(f\"Best fit mass for cluster 2 = {m_est2:.2e} +/- {m_est_err2:.2e} Msun\")\n",
    "print(f\"Best fit mass for cluster 3 = {m_est3:.2e} +/- {m_est_err3:.2e} Msun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the reconstructed mass is biased whenever the sources are not located at a single redshift as this was not accounted for in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the results\n",
    "\n",
    "For visualization purpose, we calculate the reduced tangential shear predicted by the model when using the average redshift of the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.logspace(-0.5, np.log10(5), 100)\n",
    "moo.set_mass(m_est1)\n",
    "gt_model1 = moo.eval_reduced_tangential_shear(rr, cluster_z, np.mean(cl1.galcat[\"z\"]))\n",
    "moo.set_mass(m_est2)\n",
    "gt_model2 = moo.eval_reduced_tangential_shear(rr, cluster_z, np.mean(cl2.galcat[\"z\"]))\n",
    "moo.set_mass(m_est3)\n",
    "gt_model3 = moo.eval_reduced_tangential_shear(rr, cluster_z, np.mean(cl3.galcat[\"z\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize that prediction of reduced tangential shear along with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "axes[0].errorbar(\n",
    "    profile1[\"radius\"],\n",
    "    profile1[\"gt\"],\n",
    "    profile1[\"gt_err\"],\n",
    "    color=\"red\",\n",
    "    label=\"ideal_data, M_input = %.3e Msun\" % cluster_m,\n",
    "    fmt=\".\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    rr,\n",
    "    gt_model1,\n",
    "    color=\"red\",\n",
    "    label=\"best fit model 1, M_fit = %.2e +/- %.2e\" % (m_est1, m_est_err1),\n",
    ")\n",
    "\n",
    "\n",
    "axes[0].errorbar(\n",
    "    profile2[\"radius\"],\n",
    "    profile2[\"gt\"],\n",
    "    profile2[\"gt_err\"],\n",
    "    color=\"green\",\n",
    "    label=\"ideal_data_z, M_input = %.3e Msun\" % cluster_m,\n",
    "    fmt=\".\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    rr,\n",
    "    gt_model2,\n",
    "    color=\"green\",\n",
    "    label=\"best fit model 2, M_fit = %.2e +/- %.2e\" % (m_est2, m_est_err2),\n",
    ")\n",
    "axes[0].set_title(\"Ideal data w/wo src redshift distribution\", fontsize=fsize)\n",
    "axes[0].semilogx()\n",
    "axes[0].semilogy()\n",
    "axes[0].legend(fontsize=fsize)\n",
    "axes[0].set_xlabel(\"R [Mpc]\", fontsize=fsize)\n",
    "axes[0].set_ylabel(\"reduced tangential shear\", fontsize=fsize)\n",
    "\n",
    "axes[1].errorbar(\n",
    "    profile3[\"radius\"],\n",
    "    profile3[\"gt\"],\n",
    "    profile3[\"gt_err\"],\n",
    "    color=\"red\",\n",
    "    label=\"noisy_data_z, M_input = %.3e Msun\" % cluster_m,\n",
    "    fmt=\".\",\n",
    ")\n",
    "axes[1].plot(\n",
    "    rr,\n",
    "    gt_model3,\n",
    "    color=\"red\",\n",
    "    label=\"best fit model 3, M_fit = %.2e +/- %.2e\" % (m_est3, m_est_err3),\n",
    ")\n",
    "axes[1].set_title(\"Noisy data with src redshift distribution\", fontsize=fsize)\n",
    "axes[1].semilogx()\n",
    "axes[1].semilogy()\n",
    "axes[1].legend(fontsize=fsize)\n",
    "axes[1].set_xlabel(\"R [Mpc]\", fontsize=fsize)\n",
    "axes[1].set_ylabel(\"reduced tangential shear\", fontsize=fsize)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

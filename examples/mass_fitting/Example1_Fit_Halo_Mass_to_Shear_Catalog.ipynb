{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Ideal data\n",
    "## Fit halo mass to shear profile with ideal data\n",
    "\n",
    "_the LSST-DESC CLMM team_\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use `clmm` to estimate a WL halo mass of a galaxy cluster in the ideal case: i) all galaxies on a single source plane, ii) no redshift errors, iii) no shape noise. The steps below correspond to:\n",
    "- Setting things up, with the proper imports.\n",
    "- Generating a ideal mock dataset.\n",
    "- Computing the binned reduced tangential shear profile, for two different binning scheme.\n",
    "- Setting up the model to be fitted to the data.\n",
    "- Perform a simple fit using `scipy.optimize.basinhopping` and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import `clmm`'s core modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clmm\n",
    "import clmm.dataops as da\n",
    "import clmm.galaxycluster as gc\n",
    "import clmm.theory as theory\n",
    "from clmm import Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we know which version we're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clmm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import a support modules for a specific data sets.\n",
    "`clmm` includes support modules that enable the user to generate mock data in a format compatible with `clmm`.\n",
    "We also provide support modules for processing other specific data sets for use with `clmm`.\n",
    "Any existing support module can be used as a template for creating a new support module for another data set.\n",
    "If you do make such a support module, please do consider making a pull request so we can add it for others to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support import mock_data as mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create mock data, we need to define a true cosmology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_cosmo = Cosmology(H0=70.0, Omega_dm0=0.27 - 0.045, Omega_b0=0.045, Omega_k0=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set some parameters for a mock galaxy cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = mock_cosmo\n",
    "cluster_id = \"Awesome_cluster\"\n",
    "cluster_m = 1.0e15  # M200,m [Msun]\n",
    "cluster_z = 0.3\n",
    "src_z = 0.8\n",
    "concentration = 4\n",
    "ngals = 10000\n",
    "cluster_ra = 20.0\n",
    "cluster_dec = 30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the `mock_data` support module to generate a new galaxy catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_data = mock.generate_galaxy_catalog(\n",
    "    cluster_m,\n",
    "    cluster_z,\n",
    "    concentration,\n",
    "    cosmo,\n",
    "    src_z,\n",
    "    ngals=ngals,\n",
    "    cluster_ra=cluster_ra,\n",
    "    cluster_dec=cluster_dec,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This galaxy catalog is then converted to a `clmm.GalaxyCluster` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec, cluster_z, ideal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `clmm.GalaxyCluster` object can be pickled and saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_object.save(\"mock_GC.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any saved `clmm.GalaxyCluster` object may be read in for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = clmm.GalaxyCluster.load(\"mock_GC.pkl\")\n",
    "print(\"Cluster info = ID:\", cl.unique_id, \"; ra:\", cl.ra, \"; dec:\", cl.dec, \"; z_l :\", cl.z)\n",
    "print(\"The number of source galaxies is :\", len(cl.galcat))\n",
    "\n",
    "ra_l = cl.ra\n",
    "dec_l = cl.dec\n",
    "z = cl.z\n",
    "e1 = cl.galcat[\"e1\"]\n",
    "e2 = cl.galcat[\"e2\"]\n",
    "ra_s = cl.galcat[\"ra\"]\n",
    "dec_s = cl.galcat[\"dec\"]\n",
    "z_s = cl.galcat[\"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the distribution of galaxies on the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 15\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "hb = fig.gca().hexbin(ra_s, dec_s, gridsize=50)\n",
    "\n",
    "cb = fig.colorbar(hb)\n",
    "cb.set_label(\"Number of sources in bin\", fontsize=fsize)\n",
    "\n",
    "plt.gca().set_xlabel(r\"$\\Delta RA$\", fontsize=fsize)\n",
    "plt.gca().set_ylabel(r\"$\\Delta Dec$\", fontsize=fsize)\n",
    "plt.gca().set_title(\"Source Galaxies\", fontsize=fsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm` separates cosmology-dependent and cosmology-independent functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving observables\n",
    "\n",
    "We first demonstrate a few of the procedures one can perform on data without assuming a cosmology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing shear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.dataops.compute_tangential_and_cross_components` calculates the tangential and cross shears for each source galaxy in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, g_t, g_x = da.compute_tangential_and_cross_components(ra_l, dec_l, ra_s, dec_s, e1, e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the shear field at each galaxy location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "fig.gca().loglog(theta, g_t, \".\")\n",
    "plt.ylabel(\"reduced shear\", fontsize=fsize)\n",
    "plt.xlabel(\"angular distance [rad]\", fontsize=fsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radially binning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare the reconstructed mass under two different bin definitions. \n",
    "\n",
    "Note binning would cause fitted mass to be slightly larger than input mass. The reason is that g(r), the tangential reduced shear along cluster radius, is a convex function -- the function value after binning would be larger, but the bias becomes smaller as bin number increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges1 = da.make_bins(0.01, 3.7, 50)\n",
    "bin_edges2 = da.make_bins(0.01, 3.7, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.dataops.make_radial_profile` evaluates the average shear of the galaxy catalog in bins of radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = da.make_radial_profile(\n",
    "    [g_t, g_x, z_s],\n",
    "    theta,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=bin_edges1,\n",
    "    cosmo=cosmo,\n",
    "    z_lens=z,\n",
    "    include_empty_bins=False,\n",
    ")\n",
    "res2 = da.make_radial_profile(\n",
    "    [g_t, g_x, z_s],\n",
    "    theta,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=bin_edges2,\n",
    "    cosmo=cosmo,\n",
    "    z_lens=z,\n",
    "    include_empty_bins=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we set `include_empty_bins=False` explicitly here even though it is the default behavior. Setting the argument to `True` would also return empty bins (that is, bins with *at most one* data point in them), which would have to be excluded manually when fitting, though it might be useful e.g., when combining datasets. To clarify the behavior, consider the following comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_with_empty = da.make_radial_profile(\n",
    "    [g_t, g_x, z_s],\n",
    "    theta,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=1000,\n",
    "    cosmo=cosmo,\n",
    "    z_lens=z,\n",
    "    include_empty_bins=True,\n",
    ")\n",
    "# this is the default behavior\n",
    "res_without_empty = da.make_radial_profile(\n",
    "    [g_t, g_x, z_s],\n",
    "    theta,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=1000,\n",
    "    cosmo=cosmo,\n",
    "    z_lens=z,\n",
    "    include_empty_bins=False,\n",
    ")\n",
    "res_with_empty[\"n_src\"].size, res_without_empty[\"n_src\"].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e., 108 bins have fewer than two sources in them and are excluded by default (when setting the random seed to 11)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later use, we'll define some variables for the binned radius and tangential shear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_profile1 = res1[\"p_0\"]\n",
    "r1 = res1[\"radius\"]\n",
    "z1 = res1[\"p_2\"]\n",
    "\n",
    "gt_profile2 = res2[\"p_0\"]\n",
    "r2 = res2[\"radius\"]\n",
    "z2 = res2[\"p_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the radially binned shear for our mock galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "fig.gca().loglog(r1, gt_profile1, \".\", label=\"50 bins\")\n",
    "fig.gca().loglog(r2, gt_profile2, \"+\", markersize=15, label=\"10 bins\")\n",
    "plt.legend(fontsize=fsize)\n",
    "\n",
    "plt.gca().set_title(r\"Binned shear of source galaxies\", fontsize=fsize)\n",
    "plt.gca().set_xlabel(r\"$r\\;[Mpc]$\", fontsize=fsize)\n",
    "plt.gca().set_ylabel(r\"$g_t$\", fontsize=fsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run `make_radial_profile` direct on a `clmm.GalaxyCluster` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.compute_tangential_and_cross_components()  # You need to add the shear components first\n",
    "cl.make_radial_profile(\"Mpc\", bins=1000, cosmo=cosmo, include_empty_bins=False)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running `clmm.GalaxyCluster.make_radial_profile` object, the object acquires the `clmm.GalaxyCluster.profile` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in cl.profile.colnames:\n",
    "    cl.profile[n].format = \"%6.3e\"\n",
    "cl.profile.pprint(max_width=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the data\n",
    "\n",
    "We next demonstrate a few of the procedures one can perform once a cosmology has been chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a halo model\n",
    "\n",
    "* Note: some samplers might pass arrays of size 1 to variables being minimized. This can cause problems as clmm functions type check the input. In this function below this is corrected by converting the mass to a float: `m = float(10.**logm)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfw_to_shear_profile(logm, profile_info):\n",
    "    [r, gt_profile, z_src_rbin] = profile_info\n",
    "    m = float(10.0**logm)\n",
    "    gt_model = clmm.compute_reduced_tangential_shear(\n",
    "        r, m, concentration, cluster_z, z_src_rbin, cosmo, delta_mdef=200, halo_profile_model=\"nfw\"\n",
    "    )\n",
    "    return np.sum((gt_model - gt_profile) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a halo mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimize to find the best-fit mass for the data under the two radial binning schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support.sampler import samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The samplers['minimize'] is a local optimization function, so it does not guarantee to give consistent results (logm_est1 and logm_est2) for all logm_0, which is dependent on the np.random.seed(#) set previously. Some choices of np.random.seed(#) (e.g. set # to 1) will output a logm_0 that leads to a much larger logm_est and thus a misbehaving best-fit model. In contrast, the samplers['basinhopping'] is a global optimization function, which can give stable results regardless of the initial guesses, logm_0. Since its underlying method is the same as the samplers['minimize'], the two functions take the same arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm_0 = random.uniform(13.0, 17.0, 1)[0]\n",
    "# logm_est1 = samplers['minimize'](nfw_to_shear_profile, logm_0,args=[r1, gt_profile1, z1])[0]\n",
    "logm_est1 = samplers[\"basinhopping\"](\n",
    "    nfw_to_shear_profile, logm_0, minimizer_kwargs={\"args\": ([r1, gt_profile1, z1])}\n",
    ")[0]\n",
    "\n",
    "# logm_est2 = samplers['minimize'](nfw_to_shear_profile, logm_0,args=[r2, gt_profile2, z2])[0]\n",
    "logm_est2 = samplers[\"basinhopping\"](\n",
    "    nfw_to_shear_profile, logm_0, minimizer_kwargs={\"args\": ([r2, gt_profile2, z2])}\n",
    ")[0]\n",
    "\n",
    "m_est1 = 10.0**logm_est1\n",
    "m_est2 = 10.0**logm_est2\n",
    "\n",
    "print((m_est1, m_est2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the reduced tangential shear predicted by the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.logspace(-2, np.log10(5), 100)\n",
    "\n",
    "gt_model1 = clmm.compute_reduced_tangential_shear(\n",
    "    rr, m_est1, concentration, cluster_z, src_z, cosmo, delta_mdef=200, halo_profile_model=\"nfw\"\n",
    ")\n",
    "\n",
    "gt_model2 = clmm.compute_reduced_tangential_shear(\n",
    "    rr, m_est2, concentration, cluster_z, src_z, cosmo, delta_mdef=200, halo_profile_model=\"nfw\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the two predictions of reduced tangential shear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "fig.gca().scatter(\n",
    "    r1, gt_profile1, color=\"orange\", label=\"binned mock data 1, M_input = %.3e Msun\" % cluster_m\n",
    ")\n",
    "fig.gca().plot(rr, gt_model1, color=\"orange\", label=\"best fit model 1, M_fit = %.3e\" % m_est1)\n",
    "\n",
    "fig.gca().scatter(\n",
    "    r2,\n",
    "    gt_profile2,\n",
    "    color=\"blue\",\n",
    "    alpha=0.5,\n",
    "    label=\"binned mock data 2, M_input = %.3e Msun\" % cluster_m,\n",
    ")\n",
    "fig.gca().plot(\n",
    "    rr,\n",
    "    gt_model2,\n",
    "    color=\"blue\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.5,\n",
    "    label=\"best fit model 2, M_fit = %.3e\" % m_est2,\n",
    ")\n",
    "\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"R [Mpc]\", fontsize=fsize)\n",
    "plt.ylabel(\"reduced tangential shear\", fontsize=fsize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Account for the n(z) of sources\n",
    "## Fit halo mass to shear profile accounting for the redshift distribution of source galaxies\n",
    "\n",
    "_the LSST-DESC CLMM team_\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use `clmm` to estimate a WL halo mass from observations of a galaxy cluster when source galaxies follow a given distribution (the Chang et al. (2013) implemented in `clmm`). It uses several functionalities of the support `mock_data` module to produce mock datasets.\n",
    "\n",
    "- Setting things up, with the proper imports.\n",
    "- Generating 2 datasets: an ideal dataset with source galaxies following the Chang et al. (2013) redshift distribution; a noisy dataset where photoz errors and shape noise are also included. \n",
    "- Computing the binned reduced tangential shear profile, for the 2 datasets, using logarithmic binning.\n",
    "- Setting up the \"single source plane\" model (model1) and a model accounting for the redshift distribution (model2). As already seen in Example2, model1 will yield a biased mass reconstruction. Accounting for the redshift distribution in the model (model2) solves that issue. \n",
    "- We also add two models using the methods (to use the statistics of angular diameter distance ratio) from Applegate et al. (2014) and from Schrabback et al. (2018) respectively.\n",
    "- Perform a simple fit using `scipy.optimize.curve_fit` and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Remember to run \"python setup.py install --user\" and select \"conda-clmmenv\".\n",
    "\n",
    "import clmm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy import units\n",
    "\n",
    "clmm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import `clmm`'s core modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clmm.dataops as da\n",
    "import clmm.galaxycluster as gc\n",
    "import clmm.theory as theory\n",
    "from clmm import Cosmology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import a support modules for a specific data sets.\n",
    "`clmm` includes support modules that enable the user to generate mock data in a format compatible with `clmm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support import mock_data as mock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create mock data, we need to define a true cosmology, which is currently done with [`astropy`'s cosmology library](http://docs.astropy.org/en/stable/cosmology/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = Cosmology(H0=70.0, Omega_dm0=0.27 - 0.045, Omega_b0=0.045, Omega_k0=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set some parameters for a mock galaxy cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_m = 1.0e15  # M200,m [Msun]\n",
    "logm = np.log(cluster_m) / np.log(10)\n",
    "concentration = 4\n",
    "cluster_ra = 20.0\n",
    "cluster_dec = 90.0\n",
    "cluster_z = 0.4\n",
    "ngals = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the `mock_data` support module to generate 2 galaxy catalogs:\n",
    "- `ideal_data`: galaxies distributed according to the Chang et al. (2013) redshift distribution.\n",
    "- `noisy_data`: `ideal_data` + photoz errors + shape noise\n",
    "\n",
    "(Galaxies have a minimum redshift defined as $z_{cluster} + 0.1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_data = mock.generate_galaxy_catalog(\n",
    "    cluster_m,\n",
    "    cluster_z,\n",
    "    concentration,\n",
    "    cosmo,\n",
    "    \"chang13\",\n",
    "    zsrc_min=cluster_z + 0.1,\n",
    "    ngals=ngals,\n",
    "    cluster_ra=cluster_ra,\n",
    "    cluster_dec=cluster_dec,\n",
    ")\n",
    "noisy_data = mock.generate_galaxy_catalog(\n",
    "    cluster_m,\n",
    "    cluster_z,\n",
    "    concentration,\n",
    "    cosmo,\n",
    "    \"chang13\",\n",
    "    zsrc_min=cluster_z + 0.1,\n",
    "    shapenoise=0.05,\n",
    "    photoz_sigma_unscaled=0.05,\n",
    "    ngals=ngals,\n",
    "    cluster_ra=cluster_ra,\n",
    "    cluster_dec=cluster_dec,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The galaxy catalogs are converted to a `clmm.GalaxyCluster` object and may be saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = \"CL_ideal\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec, cluster_z, ideal_data)\n",
    "gc_object.save(\"ideal_GC.pkl\")\n",
    "\n",
    "cluster_id = \"CL_noisy\"\n",
    "gc_object = clmm.GalaxyCluster(cluster_id, cluster_ra, cluster_dec, cluster_z, noisy_data)\n",
    "gc_object.save(\"noisy_GC.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any saved clmm.GalaxyCluster object may be read in for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_ideal = clmm.GalaxyCluster.load(\n",
    "    \"ideal_GC.pkl\"\n",
    ")  # background galaxies distributed according to Chang et al. (2013)\n",
    "cl_noisy = clmm.GalaxyCluster.load(\"noisy_GC.pkl\")  # Chang et al. (2013) + shapenoise + photozerror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redshift of galaxies generated by mock data are distributed following the Chang et al. (2013) redshift distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(cl_ideal.galcat[\"z\"], density=True, bins=50)\n",
    "plt.axvline(x=cluster_z, color=\"orange\", label=\"cluster redshift\")\n",
    "plt.xlabel(r\"$z_{src}$\", fontsize=20)\n",
    "plt.ylabel(r\"$N(z$)\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.xlim(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing shear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.GalaxyCluster.compute_tangential_and_cross_components` calculates the tangential and cross shears for each source galaxy in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add geometry=\"flat\" as an argument; the current default is the \"curve\" geometry from astropy.\n",
    "cl_ideal.compute_tangential_and_cross_components()\n",
    "cl_noisy.compute_tangential_and_cross_components()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radially binning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = da.make_bins(0.2, 4, 15, method=\"evenlog10width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm.GalaxyCluster.make_radial_profile` evaluates the average shear of the galaxy catalog in bins of radius.\n",
    "Note the source redshifts are also binned -- so in the radial profile (table) each z value is the mean in that radial bin (details in `clmm/dataops/__init__.py: make_radial_profile()` and `clmm/utils.py: compute_radial_averages()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_ideal.make_radial_profile(\"Mpc\", bins=bin_edges, cosmo=cosmo, gal_ids_in_bins=True)\n",
    "cl_noisy.make_radial_profile(\"Mpc\", bins=bin_edges, cosmo=cosmo, gal_ids_in_bins=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, the object acquires the `clmm.GalaxyCluster.profile` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the reduced tangential shear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider three options:\n",
    "- First, the naive and *wrong* approach: the reduced tangential shear in a given radial bin $j$ is given by $g_t(\\theta_j, \\langle z_s \\rangle)$, where $\\langle z_s \\rangle$ is the average redshift in the bin. In that case, the corresponding model is simply given by the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_reduced_tangential_shear_singlez(r, logm, z_src):\n",
    "    m = 10.0**logm\n",
    "    gt_model = clmm.compute_reduced_tangential_shear(\n",
    "        r, m, concentration, cluster_z, z_src, cosmo, delta_mdef=200, halo_profile_model=\"nfw\"\n",
    "    )\n",
    "    return gt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second, the reduced tangential shear in a given radial bin accounts properly for the redshift distribution in the bin as $\\langle g_t(\\theta_j, z_s)\\rangle \\neq g_t(\\theta_j, \\langle z_s \\rangle$). Formally, the reduced tangential shear that corresponds to a continuous distribution of source galaxy redshift $N(z)$ can be expressed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g_t(\\theta) = \\langle g_t(\\theta, z_s)\\rangle_{z_{cluster}} = \\int_{z_{cluster}}^{+\\infty}dz_sN(z_s)g_t(\\theta, z_s)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the inidividual redshifts of the background galaxies are known, we can directly build a model based on data, such that in the bin $j$: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g_t(\\theta_j) = \\frac{1}{N(\\theta_j)}\\sum\\limits_{i = 1}^{N(\\theta)}g_t(\\theta_j, z_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $N(\\theta_j)$ is the number of galaxies in bin $j$. The corresponding model is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_reduced_tangential_shear_zdistrib(radius, logm, catalog, profile):\n",
    "    m = 10**logm\n",
    "    gt_model = []\n",
    "    for i in range(len(radius)):\n",
    "        r = profile[\"radius\"][i]\n",
    "        galist = profile[\"gal_id\"][i]\n",
    "        z_list = catalog.galcat[\"z\"][galist]\n",
    "        shear = clmm.compute_reduced_tangential_shear(\n",
    "            r, m, concentration, cluster_z, z_list, cosmo, delta_mdef=200, halo_profile_model=\"nfw\"\n",
    "        )\n",
    "        gt_model.append(np.mean(shear))\n",
    "\n",
    "    return gt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Third, we consider two models that use the statistics of angular diameter distance ratio ($\\beta_s$, i.e. $\\langle\\beta_s\\rangle$, $\\langle\\beta^2_s\\rangle>$). They are similar to the ones we showed in the notebook for paper v1.0 (`gt_and_use_case.ipynb`) and the notebook for real data (Example4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define two (reduced) shear estimates by using the statistics of beta_s.\n",
    "# We expect the results will be close to the second method above.\n",
    "\n",
    "# Here beta_s are calculated inside these functions using the distribution in Chang et al. (2013).\n",
    "# But beta_s_mean and beta_s_square_mean can also be given from outside.\n",
    "# See details in these scripts below.\n",
    "# clmm/theory/func_layer.py: compute_reduced_tangential_shear()\n",
    "# clmm/theory/parent_class.py: eval_reduced_tangential_shear()\n",
    "\n",
    "# The method from Applegate et al. (2014), called 'order1' in CLMM.\n",
    "# The argument \"profile\" is only used to get the radius values r = profile['radius']\n",
    "# The default mass is M200m; use massdef='critical' for M200c.\n",
    "\n",
    "\n",
    "def _model_reduced_tangential_shear(logm, catalog, profile, approx):\n",
    "    beta_kwargs = {\n",
    "        \"z_cl\": cluster_z,\n",
    "        \"z_inf\": 10.0,\n",
    "        \"cosmo\": cosmo,\n",
    "        #'zmax' :zsrc_max,\n",
    "        #'delta_z_cut': delta_z_cut,\n",
    "        #'zmin': None,\n",
    "        # We provide the redshift distribution (default: Chang et al. 2013) for calculating the beta_s statistics\n",
    "        \"z_distrib_func\": clmm.redshift.distributions.chang2013,\n",
    "    }\n",
    "    beta_s_mean = clmm.utils.compute_beta_s_mean_from_distribution(**beta_kwargs)\n",
    "    beta_s_square_mean = clmm.utils.compute_beta_s_square_mean_from_distribution(**beta_kwargs)\n",
    "\n",
    "    gt_model = clmm.compute_reduced_tangential_shear(\n",
    "        r_proj=profile[\"radius\"],  # Radial component of the profile\n",
    "        mdelta=10**logm,  # Mass of the cluster [M_sun]\n",
    "        cdelta=concentration,  # Concentration of the cluster\n",
    "        z_cluster=cluster_z,  # Redshift of the cluster\n",
    "        z_src=[beta_s_mean, beta_s_square_mean],\n",
    "        cosmo=cosmo,\n",
    "        delta_mdef=200,\n",
    "        # massdef='critical',\n",
    "        halo_profile_model=\"nfw\",\n",
    "        z_src_info=\"beta\",\n",
    "        approx=approx,\n",
    "        # beta_s_mean=None,\n",
    "        # beta_s_square_mean=None\n",
    "    )\n",
    "    return gt_model\n",
    "\n",
    "\n",
    "def model_reduced_tangential_shear_applegate14(logm, catalog, profile):\n",
    "    return _model_reduced_tangential_shear(logm, catalog, profile, approx=\"order1\")\n",
    "\n",
    "\n",
    "# Similarly, we also consider the method from Schrabback et al. (2018), called 'order2' in CLMM.\n",
    "def model_reduced_tangential_shear_schrabback18(logm, catalog, profile):\n",
    "    return _model_reduced_tangential_shear(logm, catalog, profile, approx=\"order2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before fitting, let's first vizualise these models using the known true mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = np.log10(cluster_m)\n",
    "r = cl_ideal.profile[\"radius\"]\n",
    "\n",
    "gt_model_ideal_singlez = model_reduced_tangential_shear_singlez(r, logm, cl_ideal.profile[\"z\"])\n",
    "gt_model_ideal_zdistrib = model_reduced_tangential_shear_zdistrib(\n",
    "    r, logm, cl_ideal, cl_ideal.profile\n",
    ")\n",
    "gt_model_ideal_applegate14 = model_reduced_tangential_shear_applegate14(\n",
    "    logm, cl_ideal, cl_ideal.profile\n",
    ")\n",
    "gt_model_ideal_schrabback18 = model_reduced_tangential_shear_schrabback18(\n",
    "    logm, cl_ideal, cl_ideal.profile\n",
    ")\n",
    "\n",
    "# Noisy data can have some source redshifts that are lower than the cluster redshift.\n",
    "gt_model_noisy_singlez = model_reduced_tangential_shear_singlez(r, logm, cl_noisy.profile[\"z\"])\n",
    "gt_model_noisy_zdistrib = model_reduced_tangential_shear_zdistrib(\n",
    "    r, logm, cl_noisy, cl_noisy.profile\n",
    ")\n",
    "gt_model_noisy_applegate14 = model_reduced_tangential_shear_applegate14(\n",
    "    logm, cl_noisy, cl_noisy.profile\n",
    ")\n",
    "gt_model_noisy_schrabback18 = model_reduced_tangential_shear_schrabback18(\n",
    "    logm, cl_noisy, cl_noisy.profile\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The blue solid curve and red/green dotted curves are expected to be close (especially when g is small, i.e., large radii).\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.title(\"ideal data\", fontsize=20)\n",
    "plt.errorbar(\n",
    "    r,\n",
    "    cl_ideal.profile[\"gt\"],\n",
    "    cl_ideal.profile[\"gt_err\"],\n",
    "    c=\"k\",\n",
    "    linestyle=\"\",\n",
    "    marker=\"o\",\n",
    "    label=r\"ideal data, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_model_ideal_zdistrib,\n",
    "    \"-b\",\n",
    "    label=r\"w/ zdistrib, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_model_ideal_singlez,\n",
    "    \"-y\",\n",
    "    label=r\"w/o zdistrib, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_model_ideal_applegate14,\n",
    "    \":r\",\n",
    "    label=r\"applegate14, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_model_ideal_schrabback18,\n",
    "    \":g\",\n",
    "    label=r\"schrabback18, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"r [Mpc]\", fontsize=20)\n",
    "plt.ylabel(r\"$g_t$\", fontsize=20)\n",
    "plt.xlim(min(cl_ideal.profile[\"radius\"]), max(cl_ideal.profile[\"radius\"]))\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.title(\"noisy data\", fontsize=20)\n",
    "plt.errorbar(\n",
    "    r,\n",
    "    cl_noisy.profile[\"gt\"],\n",
    "    cl_noisy.profile[\"gt_err\"],\n",
    "    c=\"k\",\n",
    "    linestyle=\"\",\n",
    "    marker=\"o\",\n",
    "    label=r\"noisy data, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_model_noisy_zdistrib,\n",
    "    \"-b\",\n",
    "    label=r\"w/ zdistrib, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_model_noisy_singlez,\n",
    "    \"-y\",\n",
    "    label=r\"w/o zdistrib, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_model_noisy_applegate14,\n",
    "    \":r\",\n",
    "    label=r\"applegate14, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_model_noisy_schrabback18,\n",
    "    \":g\",\n",
    "    label=r\"schrabback18, $M_{input}$ = %.2e Msun\" % cluster_m,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"r [Mpc]\", fontsize=20)\n",
    "plt.ylabel(r\"$g_t$\", fontsize=20)\n",
    "plt.xlim(min(cl_noisy.profile[\"radius\"]), max(cl_noisy.profile[\"radius\"]))\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive model that uses the average redshift in the bin clearly does not give the right description of the ideal data (left panel), and will yield biased mass results if used for fitting (see below). For ideal data, the model that accounts for the redshift distribution is, by construction, an excellent description of the data (solid blue line). The same is true for noisy data (right panel), although the noise make the naive model appear \"less biased\". \n",
    "The models from Applegate et al. (2014) and Schrabback et al. (2018) give close results to the input data for both ideal and noisy data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the best-fit mass using `scipy.optimize.curve_fit`.  We compare estimated mass for noisy and ideal data, using all models described above (naive with average redshift or the model taking into account the redshift distribution, and also the ones using $\\beta_s$). The choice of fitting $\\log_{10} M$ instead of $M$ lowers the range of pre-defined fitting bounds from several order of magnitude for the mass to unity. From the associated error $\\Delta (\\log_{10}M)$ we calculate the error to mass as $\\Delta M = M_{fit}\\log(10)\\Delta (\\log_{10}M)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support.sampler import fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: model_reduced_tangential_shear_zdistrib(r, logm, cl_ideal, cl_ideal.profile),\n",
    "    cl_ideal.profile[\"radius\"],\n",
    "    cl_ideal.profile[\"gt\"],\n",
    "    cl_ideal.profile[\"gt_err\"],\n",
    "    bounds=[10.0, 16.0],\n",
    ")\n",
    "\n",
    "m_est_ideal_zdistrib = 10.0 ** popt[0]\n",
    "m_est_err_ideal_zdistrib = m_est_ideal_zdistrib * np.sqrt(pcov[0][0]) * np.log(10)\n",
    "\n",
    "\n",
    "popt, pcov = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: model_reduced_tangential_shear_applegate14(logm, cl_ideal, cl_ideal.profile),\n",
    "    cl_ideal.profile[\"radius\"],\n",
    "    cl_ideal.profile[\"gt\"],\n",
    "    cl_ideal.profile[\"gt_err\"],\n",
    "    bounds=[10.0, 16.0],\n",
    ")\n",
    "\n",
    "m_est_ideal_applegate14 = 10.0 ** popt[0]\n",
    "m_est_err_ideal_applegate14 = m_est_ideal_applegate14 * np.sqrt(pcov[0][0]) * np.log(10)\n",
    "\n",
    "\n",
    "popt, pcov = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: model_reduced_tangential_shear_schrabback18(logm, cl_ideal, cl_ideal.profile),\n",
    "    cl_ideal.profile[\"radius\"],\n",
    "    cl_ideal.profile[\"gt\"],\n",
    "    cl_ideal.profile[\"gt_err\"],\n",
    "    bounds=[10.0, 16.0],\n",
    ")\n",
    "\n",
    "m_est_ideal_schrabback18 = 10.0 ** popt[0]\n",
    "m_est_err_ideal_schrabback18 = m_est_ideal_schrabback18 * np.sqrt(pcov[0][0]) * np.log(10)\n",
    "\n",
    "\n",
    "popt, pcov = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: model_reduced_tangential_shear_singlez(r, logm, cl_ideal.profile[\"z\"]),\n",
    "    cl_ideal.profile[\"radius\"],\n",
    "    cl_ideal.profile[\"gt\"],\n",
    "    cl_ideal.profile[\"gt_err\"],\n",
    "    bounds=[10.0, 17.0],\n",
    ")\n",
    "\n",
    "m_est_ideal_singlez = 10.0 ** popt[0]\n",
    "m_est_err_ideal_singlez = m_est_ideal_singlez * np.sqrt(pcov[0][0]) * np.log(10)\n",
    "\n",
    "\n",
    "popt, pcov = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: model_reduced_tangential_shear_zdistrib(r, logm, cl_noisy, cl_noisy.profile),\n",
    "    cl_noisy.profile[\"radius\"],\n",
    "    cl_noisy.profile[\"gt\"],\n",
    "    cl_noisy.profile[\"gt_err\"],\n",
    "    bounds=[10.0, 16.0],\n",
    ")\n",
    "\n",
    "m_est_noisy_zdistrib = 10.0 ** popt[0]\n",
    "m_est_err_noisy_zdistrib = m_est_noisy_zdistrib * np.sqrt(pcov[0][0]) * np.log(10)\n",
    "\n",
    "\n",
    "popt, pcov = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: model_reduced_tangential_shear_applegate14(logm, cl_noisy, cl_noisy.profile),\n",
    "    cl_noisy.profile[\"radius\"],\n",
    "    cl_noisy.profile[\"gt\"],\n",
    "    cl_noisy.profile[\"gt_err\"],\n",
    "    bounds=[10.0, 16.0],\n",
    ")\n",
    "\n",
    "m_est_noisy_applegate14 = 10.0 ** popt[0]\n",
    "m_est_err_noisy_applegate14 = m_est_noisy_applegate14 * np.sqrt(pcov[0][0]) * np.log(10)\n",
    "\n",
    "\n",
    "popt, pcov = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: model_reduced_tangential_shear_schrabback18(logm, cl_noisy, cl_noisy.profile),\n",
    "    cl_noisy.profile[\"radius\"],\n",
    "    cl_noisy.profile[\"gt\"],\n",
    "    cl_noisy.profile[\"gt_err\"],\n",
    "    bounds=[10.0, 16.0],\n",
    ")\n",
    "\n",
    "m_est_noisy_schrabback18 = 10.0 ** popt[0]\n",
    "m_est_err_noisy_schrabback18 = m_est_noisy_schrabback18 * np.sqrt(pcov[0][0]) * np.log(10)\n",
    "\n",
    "\n",
    "popt, pcov = fitters[\"curve_fit\"](\n",
    "    lambda r, logm: model_reduced_tangential_shear_singlez(r, logm, cl_noisy.profile[\"z\"]),\n",
    "    cl_noisy.profile[\"radius\"],\n",
    "    cl_noisy.profile[\"gt\"],\n",
    "    cl_noisy.profile[\"gt_err\"],\n",
    "    bounds=[10.0, 16.0],\n",
    ")\n",
    "\n",
    "m_est_noisy_singlez = 10.0 ** popt[0]\n",
    "m_est_err_noisy_singlez = m_est_noisy_singlez * np.sqrt(pcov[0][0]) * np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"The input mass = {cluster_m:.2e} Msun\\n\")\n",
    "\n",
    "_prt_mfit = lambda mass, mass_err: f\"{mass*1e-14:.2f} +/- {mass_err*1e-14:.2f} x 10^14 Msun\"\n",
    "\n",
    "print(\"Without accounting for the redshift distribution in the model\\n\")\n",
    "print(f\"Best fit mass for ideal data = {_prt_mfit(m_est_ideal_singlez, m_est_err_ideal_singlez)}\")\n",
    "print(f\"Best fit mass for noisy data = {_prt_mfit(m_est_noisy_singlez, m_est_err_noisy_singlez)}\\n\")\n",
    "\n",
    "print(\"Accounting for the redshift distribution in the model\\n\")\n",
    "print(f\"Best fit mass for ideal data = {_prt_mfit(m_est_ideal_zdistrib, m_est_err_ideal_zdistrib)}\")\n",
    "print(\n",
    "    f\"Best fit mass for noisy data = {_prt_mfit(m_est_noisy_zdistrib, m_est_err_noisy_zdistrib)}\\n\"\n",
    ")\n",
    "\n",
    "print(\"Using applegate14 (Applegate et al. 2014)\\n\")\n",
    "print(\n",
    "    f\"Best fit mass for ideal data = {_prt_mfit(m_est_ideal_applegate14, m_est_err_ideal_applegate14)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Best fit mass for noisy data = {_prt_mfit(m_est_noisy_applegate14, m_est_err_noisy_applegate14)}\\n\"\n",
    ")\n",
    "\n",
    "print(\"Using schrabback18 (Schrabback et al. 2018)\\n\")\n",
    "print(\n",
    "    f\"Best fit mass for ideal data = {_prt_mfit(m_est_ideal_schrabback18, m_est_err_ideal_schrabback18)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Best fit mass for noisy data = {_prt_mfit(m_est_noisy_schrabback18, m_est_err_noisy_schrabback18)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the reconstructed mass is biased when the redshift distribution is not accounted for in the model; the method of applegate14 (Applegate et al. 2014) and the method of schrabback18 (Schrabback et al. 2018) give close results to the one that accounts for the redshift distribution (and to the input mass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purpose, we calculate the reduced tangential shear predicted by the models with estimated masses for noisy and ideal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_est_ideal_zdistrib = model_reduced_tangential_shear_zdistrib(\n",
    "    r, np.log(m_est_ideal_zdistrib) / np.log(10), cl_ideal, cl_ideal.profile\n",
    ")\n",
    "gt_est_noisy_zdistrib = model_reduced_tangential_shear_zdistrib(\n",
    "    r, np.log(m_est_noisy_zdistrib) / np.log(10), cl_noisy, cl_noisy.profile\n",
    ")\n",
    "gt_est_ideal_applegate14 = model_reduced_tangential_shear_applegate14(\n",
    "    np.log(m_est_ideal_applegate14) / np.log(10), cl_ideal, cl_ideal.profile\n",
    ")\n",
    "gt_est_noisy_applegate14 = model_reduced_tangential_shear_applegate14(\n",
    "    np.log(m_est_noisy_applegate14) / np.log(10), cl_noisy, cl_noisy.profile\n",
    ")\n",
    "gt_est_ideal_schrabback18 = model_reduced_tangential_shear_schrabback18(\n",
    "    np.log(m_est_ideal_schrabback18) / np.log(10), cl_ideal, cl_ideal.profile\n",
    ")\n",
    "gt_est_noisy_schrabback18 = model_reduced_tangential_shear_schrabback18(\n",
    "    np.log(m_est_noisy_schrabback18) / np.log(10), cl_noisy, cl_noisy.profile\n",
    ")\n",
    "\n",
    "gt_est_ideal_singlez = model_reduced_tangential_shear_singlez(\n",
    "    r, np.log(m_est_ideal_singlez) / np.log(10), cl_ideal.profile[\"z\"]\n",
    ")\n",
    "gt_est_noisy_singlez = model_reduced_tangential_shear_singlez(\n",
    "    r, np.log(m_est_noisy_singlez) / np.log(10), cl_noisy.profile[\"z\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare to tangential shear obtained with theoretical mass. We plot the reduced tangential shear models first when redshift distribution is accounted for in the model (and the ones using $\\beta_s$) then for the naive approach, with respective best-fit masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prt_mfit_lab = (\n",
    "    lambda mass, mass_err: rf\"${mass*1e-14:.2f} (\\pm {mass_err*1e-14:.2f}) \\times 10^{{14}}$ $M_\\odot$\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(r\"tangential shear $g_t$ (ideal data)\", fontsize=20)\n",
    "plt.errorbar(\n",
    "    r,\n",
    "    cl_ideal.profile[\"gt\"],\n",
    "    cl_ideal.profile[\"gt_err\"],\n",
    "    c=\"k\",\n",
    "    linestyle=\"\",\n",
    "    marker=\"o\",\n",
    "    label=rf\"ideal data, $M_{{input}}$ = ${cluster_m*1e-14:.2f} \\times 10^{{14}}$ $M_\\odot$\",\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_est_ideal_zdistrib,\n",
    "    \"-b\",\n",
    "    label=rf\"w/ zdistrib, M_fit = {_prt_mfit_lab(m_est_ideal_zdistrib, m_est_err_ideal_zdistrib)}\",\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_est_ideal_applegate14,\n",
    "    \":r\",\n",
    "    label=rf\"applegate14, M_fit = {_prt_mfit_lab(m_est_ideal_applegate14, m_est_err_ideal_applegate14)}\",\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_est_ideal_schrabback18,\n",
    "    \":g\",\n",
    "    label=rf\"schrabback18, M_fit = {_prt_mfit_lab(m_est_ideal_schrabback18, m_est_err_ideal_schrabback18)}\",\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_est_ideal_singlez,\n",
    "    \"-y\",\n",
    "    label=rf\"w/o zdistrib, M_fit = {_prt_mfit_lab(m_est_ideal_singlez, m_est_err_ideal_singlez)}\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"r [Mpc]\", fontsize=20)\n",
    "plt.ylabel(r\"$g_t$\", fontsize=20)\n",
    "plt.xlim(min(cl_ideal.profile[\"radius\"]), max(cl_ideal.profile[\"radius\"]))\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(r\"tangential shear $g_t$ (noisy data)\", fontsize=20)\n",
    "plt.errorbar(\n",
    "    r,\n",
    "    cl_noisy.profile[\"gt\"],\n",
    "    cl_noisy.profile[\"gt_err\"],\n",
    "    c=\"k\",\n",
    "    linestyle=\"\",\n",
    "    marker=\"o\",\n",
    "    label=rf\"noisy data, $M_{{input}}$ = ${cluster_m*1e-14:.2f} \\times 10^{{14}}$ $M_\\odot$\",\n",
    ")\n",
    "# plt.loglog(r,gt_model_noisy,'-r',  label='model, $M_{input}$ = %.3e Msun' % cluster_m)\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_est_noisy_zdistrib,\n",
    "    \"-b\",\n",
    "    label=rf\"w/ zdistrib, M_fit = {_prt_mfit_lab(m_est_noisy_zdistrib, m_est_err_noisy_zdistrib)}\",\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_est_noisy_applegate14,\n",
    "    \":r\",\n",
    "    label=rf\"applegate14, M_fit = {_prt_mfit_lab(m_est_noisy_applegate14, m_est_err_noisy_applegate14)}\",\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_est_noisy_schrabback18,\n",
    "    \":g\",\n",
    "    label=rf\"schrabback18, M_fit = {_prt_mfit_lab(m_est_noisy_schrabback18, m_est_err_noisy_schrabback18)}\",\n",
    ")\n",
    "plt.loglog(\n",
    "    r,\n",
    "    gt_est_noisy_singlez,\n",
    "    \"-y\",\n",
    "    label=rf\"w/o zdistrib, M_fit = {_prt_mfit_lab(m_est_noisy_singlez, m_est_err_noisy_singlez)}\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"r [Mpc]\", fontsize=20)\n",
    "plt.ylabel(r\"$g_t$\", fontsize=20)\n",
    "plt.xlim(min(cl_noisy.profile[\"radius\"]), max(cl_noisy.profile[\"radius\"]))\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the reconstruction of mass is biased when redshift distribution is not accounted for in the model, and is smaller compared to the input mass. It is associated to the increase of the reduced tangential shear with the source redshift $z_s$ for a given radius $r$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

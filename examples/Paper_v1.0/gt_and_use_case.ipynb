{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API demonstration for paper of v1.0\n",
    "\n",
    "_the LSST-DESC CLMM team_\n",
    "\n",
    "\n",
    "Here we demonstrate how to use `clmm` to estimate a WL halo mass from observations of a galaxy cluster when source galaxies follow a given distribution (The LSST DESC Science Requirements Document - arXiv:1809.01669,  implemented in `clmm`). It uses several functionalities of the support `mock_data` module to produce mock datasets.\n",
    "\n",
    "- Setting things up, with the proper imports.\n",
    "- Computing the binned reduced tangential shear profile, for the 2 datasets, using logarithmic binning.\n",
    "- Setting up a model accounting for the redshift distribution.\n",
    "- Perform a simple fit using `scipy.optimize.curve_fit` included in `clmm` and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"gothambook\", \"gotham\", \"gotham-book\", \"serif\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating mock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmm` has a support code to generate a mock catalog given a input cosmology and cluster parameters. We will use this to generate a data sample to be used in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm import Cosmology\n",
    "import clmm.support.mock_data as mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(14)  # For reproducibility\n",
    "\n",
    "# Set cosmology of mock data\n",
    "cosmo = Cosmology(H0=70.0, Omega_dm0=0.27 - 0.045, Omega_b0=0.045, Omega_k0=0.0)\n",
    "\n",
    "# Cluster info\n",
    "cluster_m = 1.0e15  # Cluster mass - ($M200_m$) [Msun]\n",
    "concentration = 4  # Cluster concentration\n",
    "cluster_z = 0.3  # Cluster redshift\n",
    "cluster_ra = 0.0  # Cluster Ra in deg\n",
    "cluster_dec = 0.0  # Cluster Dec in deg\n",
    "\n",
    "# Catalog info\n",
    "field_size = 10  # i.e. 10 x 10 Mpc field at the cluster redshift, cluster in the center\n",
    "\n",
    "# Make mock galaxies\n",
    "mock_galaxies = mock.generate_galaxy_catalog(\n",
    "    cluster_m=cluster_m,\n",
    "    cluster_z=cluster_z,\n",
    "    cluster_c=concentration,  # Cluster data\n",
    "    cosmo=cosmo,  # Cosmology object\n",
    "    zsrc=\"desc_srd\",  # Galaxy redshift distribution,\n",
    "    zsrc_min=0.4,  # Minimum redshift of the galaxies\n",
    "    shapenoise=0.05,  # Gaussian shape noise to the galaxy shapes\n",
    "    photoz_sigma_unscaled=0.05,  # Photo-z errors to source redshifts\n",
    "    field_size=field_size,\n",
    "    ngal_density=20,  # number of gal/arcmin2 for z in [0, infty]\n",
    "    pzpdf_type='individual_bins',\n",
    ")[\"ra\", \"dec\", \"e1\", \"e2\", \"z\", \"ztrue\", \"pzbins\", \"pzpdf\", \"id\"]\n",
    "print(f'Catalog table with the columns: {\", \".join(mock_galaxies.colnames)}')\n",
    "\n",
    "ngals_init = len(mock_galaxies)\n",
    "print(f\"Initial number of galaxies: {ngals_init:,}\")\n",
    "\n",
    "# Keeping only galaxies with \"measured\" redshift greater than cluster redshift\n",
    "mock_galaxies = mock_galaxies[(mock_galaxies[\"z\"] > cluster_z)]\n",
    "ngals_good = len(mock_galaxies)\n",
    "\n",
    "if ngals_good < ngals_init:\n",
    "    print(f\"Number of excluded galaxies (with photoz < cluster_z): {ngals_init-ngals_good:,}\")\n",
    "    # reset galaxy id for later use\n",
    "    mock_galaxies[\"id\"] = np.arange(ngals_good)\n",
    "\n",
    "# Check final density\n",
    "from clmm.utils import convert_units\n",
    "\n",
    "field_size_arcmin = convert_units(field_size, \"Mpc\", \"arcmin\", redshift=cluster_z, cosmo=cosmo)\n",
    "print(f\"Background galaxy density = {ngals_good/field_size_arcmin**2:.2f} gal/arcmin2\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the column of this mock catalog to show explicitely how the quantities can be used on `clmm` functionality and how to add them to a `GalaxyCluster` object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put galaxy values on arrays\n",
    "gal_ra = mock_galaxies[\"ra\"]  # Galaxies Ra in deg\n",
    "gal_dec = mock_galaxies[\"dec\"]  # Galaxies Dec in deg\n",
    "gal_e1 = mock_galaxies[\"e1\"]  # Galaxies elipticipy 1\n",
    "gal_e2 = mock_galaxies[\"e2\"]  # Galaxies elipticipy 2\n",
    "gal_z = mock_galaxies[\"z\"]  # Galaxies observed redshift\n",
    "gal_ztrue = mock_galaxies[\"ztrue\"]  # Galaxies true redshift\n",
    "gal_pzbins = mock_galaxies[\"pzbins\"]  # Galaxies P(z) bins\n",
    "gal_pzpdf = mock_galaxies[\"pzpdf\"]  # Galaxies P(z)\n",
    "gal_id = mock_galaxies[\"id\"]  # Galaxies ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring shear profiles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the source galaxy quantities, we can compute the elepticities and corresponding radial profile usimg `clmm.dataops` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clmm.dataops as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert elipticities into shears\n",
    "gal_ang_dist, gal_gt, gal_gx = da.compute_tangential_and_cross_components(\n",
    "    cluster_ra, cluster_dec, gal_ra, gal_dec, gal_e1, gal_e2, geometry=\"flat\"\n",
    ")\n",
    "\n",
    "# Measure profile\n",
    "profile = da.make_radial_profile(\n",
    "    [gal_gt, gal_gx, gal_z],\n",
    "    gal_ang_dist,\n",
    "    \"radians\",\n",
    "    \"Mpc\",\n",
    "    bins=da.make_bins(0.01, field_size / 2.0, 50),\n",
    "    cosmo=cosmo,\n",
    "    z_lens=cluster_z,\n",
    "    include_empty_bins=False,\n",
    ")\n",
    "print(f'Profile table has columns: {\", \".join(profile.colnames)},')\n",
    "print(\"where p_(0, 1, 2) = (gt, gx, z)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other possibility is to use the `GalaxyCluster` object. This is the main approach to handle data with `clmm`, and also the simpler way. For that you just have to provide the following information of the cluster:\n",
    "\n",
    "* Ra, Dec [deg]\n",
    "* Mass - ($M200_m$) [Msun]\n",
    "* Concentration\n",
    "* Redshift\n",
    "\n",
    "\n",
    "and the source galaxies:\n",
    "\n",
    "* Ra, Dec [deg]\n",
    "* 2 axis of eliptticities\n",
    "* Redshift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GCData with the galaxies\n",
    "galaxies = clmm.GCData(\n",
    "    [gal_ra, gal_dec, gal_e1, gal_e2, gal_z, gal_ztrue, gal_pzbins, gal_pzpdf, gal_id],\n",
    "    names=[\"ra\", \"dec\", \"e1\", \"e2\", \"z\", \"ztrue\", \"pzbins\", \"pzpdf\", \"id\"],\n",
    ")\n",
    "\n",
    "# Create a GalaxyCluster\n",
    "cluster = clmm.GalaxyCluster(\"Name of cluster\", cluster_ra, cluster_dec, cluster_z, mock_galaxies)\n",
    "\n",
    "# Convert elipticities into shears for the members\n",
    "cluster.compute_tangential_and_cross_components(geometry=\"flat\")\n",
    "print(cluster.galcat.colnames)\n",
    "\n",
    "# Measure profile and add profile table to the cluster\n",
    "seps = convert_units(cluster.galcat[\"theta\"], \"radians\", \"mpc\", cluster.z, cosmo)\n",
    "\n",
    "cluster.make_radial_profile(\n",
    "    bins=da.make_bins(0.1, field_size / 2.0, 25, method=\"evenlog10width\"),\n",
    "    bin_units=\"Mpc\",\n",
    "    cosmo=cosmo,\n",
    "    include_empty_bins=False,\n",
    "    gal_ids_in_bins=True,\n",
    ")\n",
    "print(cluster.profile.colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in an attribute `table` added to the `cluster` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_formating import prep_plot\n",
    "\n",
    "prep_plot(figsize=(9, 9))\n",
    "errorbar_kwargs = dict(linestyle=\"\", marker=\"o\", markersize=1, elinewidth=0.5, capthick=0.5)\n",
    "plt.errorbar(\n",
    "    cluster.profile[\"radius\"],\n",
    "    cluster.profile[\"gt\"],\n",
    "    cluster.profile[\"gt_err\"],\n",
    "    c=\"k\",\n",
    "    **errorbar_kwargs\n",
    ")\n",
    "plt.xlabel(\"r [Mpc]\", fontsize=10)\n",
    "plt.ylabel(r\"$g_t$\", fontsize=10)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical predictions\n",
    "\n",
    "We consider 3 models:\n",
    "1. One model where all sources are considered at the same redshift\n",
    "2. One model using the overall source redshift distribution to predict the reduced tangential shear\n",
    "3. A more accurate model, relying on the fact that we have access to the individual redshifts of the sources, where the average reduced tangential shear is averaged independently in each bin, accounting for the acutal population of sources in each bin.\n",
    "\n",
    "All models rely on `clmm.predict_reduced_tangential_shear` to make a prediction that accounts for the redshift distribution of the galaxies in each radial bin:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model considering all sources located at the average redshift\n",
    "\\begin{equation}\n",
    "     g_{t,i}^{\\rm{avg(z)}} = g_t(R_i, \\langle z \\rangle)\\;,\n",
    " \\label{eq:wrong_gt_model}\n",
    " \\end{equation} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_reduced_tangential_shear_mean_z(profile, logm):\n",
    "    return clmm.compute_reduced_tangential_shear(\n",
    "        r_proj=profile[\"radius\"],  # Radial component of the profile\n",
    "        mdelta=10**logm,  # Mass of the cluster [M_sun]\n",
    "        cdelta=4,  # Concentration of the cluster\n",
    "        z_cluster=cluster_z,  # Redshift of the cluster\n",
    "        z_src=np.mean(cluster.galcat[\"z\"]),  # Mean value of source galaxies redshift\n",
    "        cosmo=cosmo,\n",
    "        delta_mdef=200,\n",
    "        halo_profile_model=\"nfw\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model relying on the overall redshift distribution of the sources N(z), not using individual redshift information (eq. (6) from Applegate et al. 2014, MNRAS, 439, 48) \n",
    "\\begin{equation}\n",
    "     g_{t,i}^{N(z)} = \\frac{\\langle\\beta_s\\rangle \\gamma_t(R_i, z\\rightarrow\\infty)}{1-\\frac{\\langle\\beta_s^2\\rangle}{\\langle\\beta_s\\rangle}\\kappa(R_i, z\\rightarrow\\infty)}\n",
    "     \\label{eq:approx_model}\n",
    " \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_inf = 1000\n",
    "dl_inf = cosmo.eval_da_z1z2(cluster_z, z_inf)\n",
    "d_inf = cosmo.eval_da(z_inf)\n",
    "\n",
    "\n",
    "def betas(z):\n",
    "    dls = cosmo.eval_da_z1z2(cluster_z, z)\n",
    "    ds = cosmo.eval_da(z)\n",
    "    return dls * d_inf / (ds * dl_inf)\n",
    "\n",
    "\n",
    "def predict_reduced_tangential_shear_approx(profile, logm):\n",
    "    bs_mean = np.mean(betas(cluster.galcat[\"z\"]))\n",
    "    bs2_mean = np.mean(betas(cluster.galcat[\"z\"]) ** 2)\n",
    "\n",
    "    gamma_t_inf = clmm.compute_tangential_shear(\n",
    "        r_proj=profile[\"radius\"],  # Radial component of the profile\n",
    "        mdelta=10**logm,  # Mass of the cluster [M_sun]\n",
    "        cdelta=4,  # Concentration of the cluster\n",
    "        z_cluster=cluster_z,  # Redshift of the cluster\n",
    "        z_src=z_inf,  # Redshift value at infinity\n",
    "        cosmo=cosmo,\n",
    "        delta_mdef=200,\n",
    "        halo_profile_model=\"nfw\",\n",
    "    )\n",
    "    convergence_inf = clmm.compute_convergence(\n",
    "        r_proj=profile[\"radius\"],  # Radial component of the profile\n",
    "        mdelta=10**logm,  # Mass of the cluster [M_sun]\n",
    "        cdelta=4,  # Concentration of the cluster\n",
    "        z_cluster=cluster_z,  # Redshift of the cluster\n",
    "        z_src=z_inf,  # Redshift value at infinity\n",
    "        cosmo=cosmo,\n",
    "        delta_mdef=200,\n",
    "        halo_profile_model=\"nfw\",\n",
    "    )\n",
    "\n",
    "    return bs_mean * gamma_t_inf / (1 - (bs2_mean / bs_mean) * convergence_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model using individual redshift and radial information, to compute the averaged shear in each radial bin, based on the galaxies actually present in that bin.\n",
    "\\begin{equation}\n",
    "    g_{t,i}^{z, R} = \\frac{1}{N_i}\\sum_{{\\rm gal\\,}j\\in {\\rm bin\\,}i} g_t(R_j, z_j)\n",
    "    \\label{eq:exact_model}\n",
    " \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.galcat[\"theta_mpc\"] = convert_units(\n",
    "    cluster.galcat[\"theta\"], \"radians\", \"mpc\", cluster.z, cosmo\n",
    ")\n",
    "\n",
    "\n",
    "def predict_reduced_tangential_shear_exact(profile, logm):\n",
    "    return np.array(\n",
    "        [\n",
    "            np.mean(\n",
    "                clmm.compute_reduced_tangential_shear(\n",
    "                    # Radial component of each source galaxy inside the radial bin\n",
    "                    r_proj=cluster.galcat[radial_bin[\"gal_id\"]][\"theta_mpc\"],\n",
    "                    mdelta=10**logm,  # Mass of the cluster [M_sun]\n",
    "                    cdelta=4,  # Concentration of the cluster\n",
    "                    z_cluster=cluster_z,  # Redshift of the cluster\n",
    "                    # Redshift value of each source galaxy inside the radial bin\n",
    "                    z_src=cluster.galcat[radial_bin[\"gal_id\"]][\"z\"],\n",
    "                    cosmo=cosmo,\n",
    "                    delta_mdef=200,\n",
    "                    halo_profile_model=\"nfw\",\n",
    "                )\n",
    "            )\n",
    "            for radial_bin in profile\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the best-fit mass using `scipy.optimize.curve_fit`. The choice of fitting $\\log M$ instead of $M$ lowers the range of pre-defined fitting bounds from several order of magnitude for the mass to unity. From the associated error $\\sigma_{\\log M}$ we calculate the error to mass as $\\sigma_M = M_{fit}\\ln(10)\\sigma_{\\log M}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, identify bins with sufficient galaxy statistics to be kept for the fit\n",
    "For small samples, error bars should not be computed using the simple error on the mean approach available so far in CLMM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_for_fit = cluster.profile[\"n_src\"] > 5\n",
    "data_for_fit = cluster.profile[mask_for_fit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the fits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clmm.support.sampler import fitters\n",
    "\n",
    "\n",
    "def fit_mass(predict_function):\n",
    "    popt, pcov = fitters[\"curve_fit\"](\n",
    "        predict_function,\n",
    "        data_for_fit,\n",
    "        data_for_fit[\"gt\"],\n",
    "        data_for_fit[\"gt_err\"],\n",
    "        bounds=[10.0, 17.0],\n",
    "    )\n",
    "    logm, logm_err = popt[0], np.sqrt(pcov[0][0])\n",
    "    return {\n",
    "        \"logm\": logm,\n",
    "        \"logm_err\": logm_err,\n",
    "        \"m\": 10**logm,\n",
    "        \"m_err\": (10**logm) * logm_err * np.log(10),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_mean_z = fit_mass(predict_reduced_tangential_shear_mean_z)\n",
    "fit_approx = fit_mass(predict_reduced_tangential_shear_approx)\n",
    "fit_exact = fit_mass(predict_reduced_tangential_shear_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Input mass = {cluster_m:.2e} Msun\\n\")\n",
    "\n",
    "print(\n",
    "    f'Best fit mass for average redshift               = {fit_mean_z[\"m\"]:.3e} +/- {fit_mean_z[\"m_err\"]:.3e} Msun'\n",
    ")\n",
    "print(\n",
    "    f'Best fit mass for N(z) model                     = {fit_approx[\"m\"]:.3e} +/- {fit_approx[\"m_err\"]:.3e} Msun'\n",
    ")\n",
    "print(\n",
    "    f'Best fit mass for individual redshift and radius = {fit_exact[\"m\"]:.3e} +/- {fit_exact[\"m_err\"]:.3e} Msun'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the reconstructed mass is biased when the redshift distribution is not accounted for in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purpose, we calculate the reduced tangential shear predicted by the model with estimated masses for noisy and ideal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_shear(predict_function, fit_values):\n",
    "    gt_est = predict_function(data_for_fit, fit_values[\"logm\"])\n",
    "    gt_est_err = [\n",
    "        predict_function(data_for_fit, fit_values[\"logm\"] + i * fit_values[\"logm_err\"])\n",
    "        for i in (-3, 3)\n",
    "    ]\n",
    "    return gt_est, gt_est_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mean_z, gt_err_mean_z = get_predicted_shear(predict_reduced_tangential_shear_mean_z, fit_mean_z)\n",
    "gt_approx, gt_err_approx = get_predicted_shear(predict_reduced_tangential_shear_approx, fit_approx)\n",
    "gt_exact, gt_err_exact = get_predicted_shear(predict_reduced_tangential_shear_exact, fit_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check reduced chi2 values of the best-fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_mean_z_dof = np.sum((gt_mean_z - data_for_fit[\"gt\"]) ** 2 / (data_for_fit[\"gt_err\"]) ** 2) / (\n",
    "    len(data_for_fit) - 1\n",
    ")\n",
    "chi2_approx_dof = np.sum((gt_approx - data_for_fit[\"gt\"]) ** 2 / (data_for_fit[\"gt_err\"]) ** 2) / (\n",
    "    len(data_for_fit) - 1\n",
    ")\n",
    "chi2_exact_dof = np.sum((gt_exact - data_for_fit[\"gt\"]) ** 2 / (data_for_fit[\"gt_err\"]) ** 2) / (\n",
    "    len(data_for_fit) - 1\n",
    ")\n",
    "\n",
    "print(f\"Reduced chi2 (mean z model) = {chi2_mean_z_dof}\")\n",
    "print(f\"Reduced chi2 (N(z) model) = {chi2_approx_dof}\")\n",
    "print(f\"Reduced chi2 (individual (R,z) model) = {chi2_exact_dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare to tangential shear obtained with theoretical mass. We plot the reduced tangential shear models first when redshift distribution is accounted for in the model then for the naive approach, with respective best-fit masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "prep_plot(figsize=(9, 9))\n",
    "gt_ax = plt.axes([0.25, 0.42, 0.7, 0.55])\n",
    "gt_ax.errorbar(\n",
    "    data_for_fit[\"radius\"],\n",
    "    data_for_fit[\"gt\"],\n",
    "    data_for_fit[\"gt_err\"],\n",
    "    c=\"k\",\n",
    "    label=rf\"$M_{{input}} = {cluster_m*1e-15}\\times10^{{{15}}} M_\\odot$\",\n",
    "    **errorbar_kwargs,\n",
    ")\n",
    "\n",
    "# Points in grey have not been used for the fit\n",
    "gt_ax.errorbar(\n",
    "    cluster.profile[\"radius\"][~mask_for_fit],\n",
    "    cluster.profile[\"gt\"][~mask_for_fit],\n",
    "    cluster.profile[\"gt_err\"][~mask_for_fit],\n",
    "    c=\"grey\",\n",
    "    **errorbar_kwargs,\n",
    ")\n",
    "\n",
    "pow10 = 15\n",
    "mlabel = (\n",
    "    lambda name, fits: rf'$M_{{fit}}^{{{name}}} = {fits[\"m\"]/10**pow10:.3f}\\pm{fits[\"m_err\"]/10**pow10:.3f}\\times 10^{{{pow10}}} M_\\odot$'\n",
    ")\n",
    "# Avg z\n",
    "gt_ax.loglog(data_for_fit[\"radius\"], gt_mean_z, \"-C0\", label=mlabel(\"avg(z)\", fit_mean_z), lw=0.5)\n",
    "gt_ax.fill_between(data_for_fit[\"radius\"], *gt_err_mean_z, lw=0, color=\"C0\", alpha=0.2)\n",
    "# Approx model\n",
    "gt_ax.loglog(data_for_fit[\"radius\"], gt_approx, \"-C1\", label=mlabel(\"N(z)\", fit_approx), lw=0.5)\n",
    "gt_ax.fill_between(data_for_fit[\"radius\"], *gt_err_approx, lw=0, color=\"C1\", alpha=0.2)\n",
    "# Exact model\n",
    "gt_ax.loglog(data_for_fit[\"radius\"], gt_exact, \"-C2\", label=mlabel(\"z,R\", fit_exact), lw=0.5)\n",
    "gt_ax.fill_between(data_for_fit[\"radius\"], *gt_err_exact, lw=0, color=\"C2\", alpha=0.2)\n",
    "\n",
    "\n",
    "gt_ax.set_ylabel(r\"$g_t$\", fontsize=8)\n",
    "gt_ax.legend(fontsize=6)\n",
    "gt_ax.set_xticklabels([])\n",
    "gt_ax.tick_params(\"x\", labelsize=8)\n",
    "gt_ax.tick_params(\"y\", labelsize=8)\n",
    "\n",
    "# gt_ax.set_yscale('log')\n",
    "errorbar_kwargs2 = {k: v for k, v in errorbar_kwargs.items() if \"marker\" not in k}\n",
    "errorbar_kwargs2[\"markersize\"] = 3\n",
    "errorbar_kwargs2[\"markeredgewidth\"] = 0.5\n",
    "res_ax = plt.axes([0.25, 0.2, 0.7, 0.2])\n",
    "delta = (cluster.profile[\"radius\"][1] / cluster.profile[\"radius\"][0]) ** 0.25\n",
    "res_err = data_for_fit[\"gt_err\"] / data_for_fit[\"gt\"]\n",
    "res_ax.errorbar(\n",
    "    data_for_fit[\"radius\"] / delta,\n",
    "    gt_mean_z / data_for_fit[\"gt\"] - 1,\n",
    "    yerr=res_err,\n",
    "    marker=\".\",\n",
    "    c=\"C0\",\n",
    "    **errorbar_kwargs2,\n",
    ")\n",
    "errorbar_kwargs2[\"markersize\"] = 1.5\n",
    "res_ax.errorbar(\n",
    "    data_for_fit[\"radius\"],\n",
    "    gt_approx / data_for_fit[\"gt\"] - 1,\n",
    "    yerr=res_err,\n",
    "    marker=\"s\",\n",
    "    c=\"C1\",\n",
    "    **errorbar_kwargs2,\n",
    ")\n",
    "errorbar_kwargs2[\"markersize\"] = 3\n",
    "errorbar_kwargs2[\"markeredgewidth\"] = 0.5\n",
    "res_ax.errorbar(\n",
    "    data_for_fit[\"radius\"] * delta,\n",
    "    gt_exact / data_for_fit[\"gt\"] - 1,\n",
    "    yerr=res_err,\n",
    "    marker=\"*\",\n",
    "    c=\"C2\",\n",
    "    **errorbar_kwargs2,\n",
    ")\n",
    "res_ax.set_xlabel(r\"$R$ [Mpc]\", fontsize=8)\n",
    "\n",
    "res_ax.set_ylabel(r\"$g_t^{mod.}/g_t^{data}-1$\", fontsize=8)\n",
    "res_ax.set_xscale(\"log\")\n",
    "res_ax.set_xlim(gt_ax.get_xlim())\n",
    "res_ax.set_ylim(-0.65, 0.65)\n",
    "res_ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "\n",
    "res_ax.tick_params(\"x\", labelsize=8)\n",
    "res_ax.tick_params(\"y\", labelsize=8)\n",
    "\n",
    "for p in (gt_ax, res_ax):\n",
    "    p.xaxis.grid(True, which=\"major\", lw=0.5)\n",
    "    p.yaxis.grid(True, which=\"major\", lw=0.5)\n",
    "    p.xaxis.grid(True, which=\"minor\", lw=0.1)\n",
    "    p.yaxis.grid(True, which=\"minor\", lw=0.1)\n",
    "\n",
    "plt.savefig(\"r_gt.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-clmmenv",
   "language": "python",
   "name": "conda-clmmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
